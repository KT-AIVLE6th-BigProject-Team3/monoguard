{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83f233-c29f-43cd-86ae-fedae5b3cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "agv 90%\n",
    "oht 94%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a740b632-704b-40ad-8f71-bd2b2cfc5987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: numpy\n",
      "Version: 1.21.6\n",
      "Summary: NumPy is the fundamental package for array computing with Python.\n",
      "Home-page: https://www.numpy.org\n",
      "Author: Travis E. Oliphant et al.\n",
      "Author-email: \n",
      "License: BSD\n",
      "Location: c:\\users\\82103\\anaconda3\\envs\\tf37\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: matplotlib, numba, opencv-python, pandas, scikit-learn, scipy, shap, tensorboard, torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1028576d-e4aa-483f-b9c6-3c69739fd149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1: Train Loss = 0.4724, Train Accuracy = 80.63%, Val Loss = 0.2270, Val Accuracy = 90.70%, Time = 115.16s\n",
      "Epoch 2: Train Loss = 0.2985, Train Accuracy = 88.10%, Val Loss = 0.1825, Val Accuracy = 92.89%, Time = 113.82s\n",
      "Epoch 3: Train Loss = 0.2567, Train Accuracy = 89.95%, Val Loss = 0.1511, Val Accuracy = 93.26%, Time = 114.43s\n",
      "Epoch 4: Train Loss = 0.2289, Train Accuracy = 90.76%, Val Loss = 0.1685, Val Accuracy = 92.84%, Time = 110.16s\n",
      "Epoch 5: Train Loss = 0.2152, Train Accuracy = 91.41%, Val Loss = 0.1518, Val Accuracy = 93.45%, Time = 109.93s\n",
      "Epoch 6: Train Loss = 0.1912, Train Accuracy = 92.22%, Val Loss = 0.1296, Val Accuracy = 94.23%, Time = 110.17s\n",
      "Epoch 7: Train Loss = 0.1865, Train Accuracy = 92.47%, Val Loss = 0.1352, Val Accuracy = 93.69%, Time = 110.35s\n",
      "Epoch 8: Train Loss = 0.1828, Train Accuracy = 92.47%, Val Loss = 0.1604, Val Accuracy = 93.69%, Time = 109.93s\n",
      "Epoch 9: Train Loss = 0.1806, Train Accuracy = 92.61%, Val Loss = 0.1257, Val Accuracy = 94.80%, Time = 110.48s\n",
      "Epoch 10: Train Loss = 0.1774, Train Accuracy = 92.73%, Val Loss = 0.1371, Val Accuracy = 94.52%, Time = 111.19s\n",
      "Epoch 11: Train Loss = 0.1665, Train Accuracy = 93.07%, Val Loss = 0.1202, Val Accuracy = 94.78%, Time = 109.40s\n",
      "Epoch 12: Train Loss = 0.1643, Train Accuracy = 93.17%, Val Loss = 0.1268, Val Accuracy = 94.77%, Time = 124.03s\n",
      "Epoch 13: Train Loss = 0.1638, Train Accuracy = 93.16%, Val Loss = 0.1213, Val Accuracy = 94.84%, Time = 113.69s\n",
      "Epoch 14: Train Loss = 0.1636, Train Accuracy = 93.27%, Val Loss = 0.1253, Val Accuracy = 94.87%, Time = 112.23s\n",
      "Epoch 15: Train Loss = 0.1639, Train Accuracy = 93.13%, Val Loss = 0.1185, Val Accuracy = 95.30%, Time = 113.11s\n",
      "Epoch 16: Train Loss = 0.1570, Train Accuracy = 93.29%, Val Loss = 0.1163, Val Accuracy = 95.15%, Time = 123.52s\n",
      "Epoch 17: Train Loss = 0.1562, Train Accuracy = 93.37%, Val Loss = 0.1133, Val Accuracy = 94.99%, Time = 115.57s\n",
      "Epoch 18: Train Loss = 0.1563, Train Accuracy = 93.41%, Val Loss = 0.1150, Val Accuracy = 95.03%, Time = 115.45s\n",
      "Epoch 19: Train Loss = 0.1550, Train Accuracy = 93.38%, Val Loss = 0.1138, Val Accuracy = 95.14%, Time = 120.81s\n",
      "Epoch 20: Train Loss = 0.1548, Train Accuracy = 93.47%, Val Loss = 0.1121, Val Accuracy = 95.26%, Time = 124.42s\n",
      "Epoch 21: Train Loss = 0.1513, Train Accuracy = 93.53%, Val Loss = 0.1165, Val Accuracy = 95.18%, Time = 129.66s\n",
      "Epoch 22: Train Loss = 0.1503, Train Accuracy = 93.61%, Val Loss = 0.1125, Val Accuracy = 95.19%, Time = 113.91s\n",
      "Epoch 23: Train Loss = 0.1504, Train Accuracy = 93.49%, Val Loss = 0.1143, Val Accuracy = 95.12%, Time = 113.42s\n",
      "Epoch 24: Train Loss = 0.1506, Train Accuracy = 93.60%, Val Loss = 0.1135, Val Accuracy = 95.08%, Time = 112.84s\n",
      "Epoch 25: Train Loss = 0.1497, Train Accuracy = 93.67%, Val Loss = 0.1119, Val Accuracy = 95.23%, Time = 112.54s\n",
      "Epoch 26: Train Loss = 0.1471, Train Accuracy = 93.81%, Val Loss = 0.1122, Val Accuracy = 95.14%, Time = 112.77s\n",
      "Epoch 27: Train Loss = 0.1471, Train Accuracy = 93.70%, Val Loss = 0.1129, Val Accuracy = 95.29%, Time = 112.94s\n",
      "Epoch 28: Train Loss = 0.1476, Train Accuracy = 93.69%, Val Loss = 0.1120, Val Accuracy = 95.40%, Time = 112.92s\n",
      "Epoch 29: Train Loss = 0.1468, Train Accuracy = 93.70%, Val Loss = 0.1114, Val Accuracy = 95.31%, Time = 112.75s\n",
      "Epoch 30: Train Loss = 0.1479, Train Accuracy = 93.67%, Val Loss = 0.1112, Val Accuracy = 95.48%, Time = 113.23s\n",
      "Epoch 31: Train Loss = 0.1461, Train Accuracy = 93.66%, Val Loss = 0.1090, Val Accuracy = 95.41%, Time = 117.49s\n",
      "Epoch 32: Train Loss = 0.1452, Train Accuracy = 93.77%, Val Loss = 0.1112, Val Accuracy = 95.37%, Time = 133.41s\n",
      "Epoch 33: Train Loss = 0.1455, Train Accuracy = 93.72%, Val Loss = 0.1096, Val Accuracy = 95.37%, Time = 121.18s\n",
      "Epoch 34: Train Loss = 0.1469, Train Accuracy = 93.70%, Val Loss = 0.1092, Val Accuracy = 95.37%, Time = 127.16s\n",
      "Epoch 35: Train Loss = 0.1459, Train Accuracy = 93.72%, Val Loss = 0.1109, Val Accuracy = 95.49%, Time = 114.28s\n",
      "Epoch 36: Train Loss = 0.1465, Train Accuracy = 93.79%, Val Loss = 0.1097, Val Accuracy = 95.55%, Time = 118.17s\n",
      "Epoch 37: Train Loss = 0.1456, Train Accuracy = 93.73%, Val Loss = 0.1104, Val Accuracy = 95.42%, Time = 106.60s\n",
      "Epoch 38: Train Loss = 0.1448, Train Accuracy = 93.72%, Val Loss = 0.1097, Val Accuracy = 95.44%, Time = 106.40s\n",
      "Early stopping at epoch 39\n",
      "Test Accuracy: 93.94%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# 1. 멀티모달 데이터셋 정의\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, csv_path, bin_root_folder, split_folder, img_dim_h, img_dim_w):\n",
    "        self.data = []\n",
    "        self.img_dim_h = img_dim_h\n",
    "        self.img_dim_w = img_dim_w\n",
    "\n",
    "        # 모든 BIN 파일의 경로 수집\n",
    "        bin_files = {}\n",
    "        split_path = os.path.join(bin_root_folder, split_folder)\n",
    "        for root, _, files in os.walk(split_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".bin\"):\n",
    "                    bin_files[file] = os.path.join(root, file)\n",
    "\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(csv_path)\n",
    "        #features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\", \"CT1\", \"CT2\", \"CT3\", \"CT4\", \"temp_max_value\"]\n",
    "        features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\", \"CT1\", \"CT2\", \"CT3\", \"CT4\", \"temp_max_value\", \"ex_temperature\", \"ex_humidity\", \"ex_illuminance\"]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            bin_filename = row['bin_filename']\n",
    "            if bin_filename in bin_files:\n",
    "                bin_path = bin_files[bin_filename]\n",
    "                try:\n",
    "                    img_data = np.load(bin_path).reshape((img_dim_h, img_dim_w))\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] BIN 파일 로드 실패: {bin_path}, {e}\")\n",
    "                    continue\n",
    "\n",
    "                aux_data = row[features].values.astype(np.float32)\n",
    "                label = int(row['state'])\n",
    "                self.data.append((img_data, aux_data, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data, aux_data, label = self.data[idx]\n",
    "        img_data = torch.tensor(img_data, dtype=torch.float32).unsqueeze(0)\n",
    "        aux_data = torch.tensor(aux_data, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img_data, aux_data, label\n",
    "\n",
    "\n",
    "# 2. 데이터 로더 함수\n",
    "def load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size=32):\n",
    "    train_dataset = MultimodalDataset(csv_path, bin_root_folder, 'train', img_dim_h, img_dim_w)\n",
    "    val_dataset = MultimodalDataset(csv_path, bin_root_folder, 'val', img_dim_h, img_dim_w)\n",
    "    test_dataset = MultimodalDataset(csv_path, bin_root_folder, 'test', img_dim_h, img_dim_w)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# 3. 모델 정의\n",
    "class ViTFeatureExtractor(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.vit = nn.Transformer(\n",
    "            d_model=embed_dim, nhead=num_heads, num_encoder_layers=depth,\n",
    "            batch_first=True, dropout=dropout_rate\n",
    "        )\n",
    "        self.patch_embed = nn.Conv2d(1, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        num_patches = (img_dim_h // patch_size) * (img_dim_w // patch_size)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches, embed_dim))\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = self.patch_embed(x).flatten(2).transpose(1, 2)\n",
    "        x = patches + self.pos_embedding\n",
    "        x = self.vit(x, x)\n",
    "        x = self.dropout(x.mean(dim=1))\n",
    "        return x\n",
    "\n",
    "\n",
    "class SoftLabelEncoder(nn.Module):\n",
    "    def __init__(self, aux_input_dim, embed_dim, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(aux_input_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, aux_data):\n",
    "        return self.fc(aux_data)\n",
    "\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, query, key):\n",
    "        attn_output, _ = self.attention(query, key, key)\n",
    "        return attn_output\n",
    "\n",
    "\n",
    "class ConditionClassifier(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, aux_input_dim, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.vit = ViTFeatureExtractor(img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate)\n",
    "        self.soft_label_encoder = SoftLabelEncoder(aux_input_dim, embed_dim, dropout_rate)\n",
    "        self.cross_attention = CrossAttention(embed_dim, num_heads)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, aux_data):\n",
    "        visual_features = self.vit(images)\n",
    "        aux_features = self.soft_label_encoder(aux_data)\n",
    "        visual_features = visual_features.unsqueeze(1)\n",
    "        aux_features = aux_features.unsqueeze(1)\n",
    "        integrated_features = self.cross_attention(visual_features, aux_features).squeeze(1)\n",
    "        return self.classifier(integrated_features)\n",
    "\n",
    "\n",
    "# 4. 학습 함수\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, num_epochs=30, patience=5):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for images, aux_data, labels in train_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, aux_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, aux_data, labels in val_loader:\n",
    "                images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "                outputs = model(images, aux_data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # ✅ 모델 전체 저장 방식으로 변경\n",
    "            torch.save(model, \"OHT/oht12_best_model.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        # Scheduler step\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {train_loss / len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy = {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss = {val_loss / len(val_loader):.4f}, \"\n",
    "              f\"Val Accuracy = {val_accuracy:.2f}%, \"\n",
    "              f\"Time = {end_time - start_time:.2f}s\")\n",
    "\n",
    "# 5. 실행\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/OHT/oht_merged_output.csv\"\n",
    "    bin_root_folder = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/OHT\"\n",
    "    img_dim_h, img_dim_w = 120, 160\n",
    "    aux_input_dim = 12\n",
    "    num_classes = 4\n",
    "    batch_size = 32\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_loader, val_loader, test_loader = load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 모델 정의\n",
    "    model = ConditionClassifier(\n",
    "        img_dim_h, img_dim_w, patch_size=16, embed_dim=128, num_heads=4,\n",
    "        depth=8, aux_input_dim=aux_input_dim, num_classes=num_classes, dropout_rate=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    # 학습\n",
    "    train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer,\n",
    "        scheduler, num_epochs=100, patience=8\n",
    "    )\n",
    "\n",
    "    # ✅ 모델 전체 로드 방식으로 변경\n",
    "    model = torch.load(\"OHT/oht12_best_model.pth\", map_location=device)\n",
    "    model.eval()\n",
    "\n",
    "    # 테스트\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7447566-8463-48e9-81d3-4053f0a96700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440e18cb-9d68-4623-a8f9-7ecb40fa6c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ 모델 불러오기 완료\n",
      "\n",
      "📊 Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9718    0.9467    0.9591      3059\n",
      "           1     0.8952    0.8997    0.8974      1804\n",
      "           2     0.9388    0.9533    0.9460      1819\n",
      "           3     0.9174    0.9758    0.9457       660\n",
      "\n",
      "    accuracy                         0.9394      7342\n",
      "   macro avg     0.9308    0.9439    0.9370      7342\n",
      "weighted avg     0.9399    0.9394    0.9395      7342\n",
      "\n",
      "Predicted Class Distribution: {0: 2980, 1: 1813, 2: 1847, 3: 702}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Feature Statistics\n",
      "\n",
      "[각 클래스별 평균값]\n",
      "                  NTC       PM10      PM2.5     PM1.0        CT1        CT2  \\\n",
      "Pred_Label                                                                    \n",
      "0           27.377306  20.011745  11.750671  7.993289   2.335574   1.098742   \n",
      "1           28.961103  20.004965  11.992278  8.024820   2.861026   3.210838   \n",
      "2           36.743519  19.992420  12.018408  7.987547   5.825403  24.698051   \n",
      "3           47.555115  19.977207  11.995727  7.985755  12.865684  97.936195   \n",
      "\n",
      "                  CT3        CT4  temp_max_value  ex_temperature  ex_humidity  \\\n",
      "Pred_Label                                                                      \n",
      "0            0.510842   0.482896       46.893539       22.510067    35.495300   \n",
      "1            1.312124   0.863403       58.835411       22.498070    35.493656   \n",
      "2            9.918013   4.553265       74.602829       22.471575    35.492149   \n",
      "3           36.780441  18.338161       88.665710       22.527065    35.501423   \n",
      "\n",
      "            ex_illuminance  \n",
      "Pred_Label                  \n",
      "0               520.341614  \n",
      "1               520.462219  \n",
      "2               520.459656  \n",
      "3               520.334778  \n",
      "Raw Logits: tensor([[  2.3404,  -0.2848, -13.5464, -27.5990],\n",
      "        [  1.6148,   2.1984,  -7.5301, -27.8349],\n",
      "        [  1.8223,   2.1614,  -8.2497, -28.6513],\n",
      "        [  1.7525,   1.7832,  -8.4788, -27.0199],\n",
      "        [  2.0628,   1.9009,  -9.4667, -29.5427]], device='cuda:0')\n",
      "Softmax Probabilities: tensor([[9.3247e-01, 6.7532e-02, 1.1751e-07, 9.2709e-14],\n",
      "        [3.5808e-01, 6.4188e-01, 3.8230e-05, 5.8094e-14],\n",
      "        [4.1602e-01, 5.8396e-01, 1.7576e-05, 2.4245e-14],\n",
      "        [4.9232e-01, 5.0766e-01, 1.7736e-05, 1.5723e-13],\n",
      "        [5.4039e-01, 4.5960e-01, 5.3147e-06, 1.0153e-14]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ✅ 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ✅ 모델 로드\n",
    "def load_trained_model(model_path):\n",
    "    model = torch.load(model_path, map_location=device)  # 저장된 모델 전체 로드\n",
    "    model.eval()  # 평가 모드\n",
    "    print(\"✅ 모델 불러오기 완료\")\n",
    "    return model\n",
    "\n",
    "# ✅ 데이터 로드\n",
    "def load_test_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size):\n",
    "    test_dataset = MultimodalDataset(csv_path, bin_root_folder, \"test\", img_dim_h, img_dim_w)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "# ✅ 테스트 실행 함수\n",
    "def evaluate_model(model, test_loader, features, num_classes):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_aux_data = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "\n",
    "            # ✅ Softmax 적용\n",
    "            temperature = 2.0  # 온도 조정\n",
    "            probs = torch.softmax(outputs / temperature, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_aux_data.extend(aux_data.cpu().numpy())\n",
    "\n",
    "    # ✅ 결과 분석\n",
    "    df_results = pd.DataFrame(all_aux_data, columns=features)\n",
    "    df_results[\"True_Label\"] = all_labels\n",
    "    df_results[\"Pred_Label\"] = all_preds\n",
    "    df_results[\"Max_Prob\"] = np.max(all_probs, axis=1)\n",
    "\n",
    "    # ✅ 모델 성능 출력\n",
    "    print(\"\\n📊 Classification Report\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "    # ✅ 예측 클래스 분포 확인\n",
    "    unique, counts = np.unique(all_preds, return_counts=True)\n",
    "    print(\"Predicted Class Distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "    # ✅ 확률 분포 시각화\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for class_idx in range(num_classes):\n",
    "        class_probs = [prob[class_idx] for prob in all_probs]\n",
    "        plt.hist(class_probs, bins=30, alpha=0.5, label=f\"Class {class_idx}\")\n",
    "\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Probability Distribution of Each Class\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # ✅ 변수별 평균값 출력\n",
    "    print(\"\\n📌 Feature Statistics\")\n",
    "    feature_means = df_results.groupby(\"Pred_Label\")[features].mean()\n",
    "    print(\"\\n[각 클래스별 평균값]\")\n",
    "    print(feature_means)\n",
    "\n",
    "    # ✅ Softmax가 특정 클래스에 몰리는지 확인\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "            print(\"Raw Logits:\", outputs[:5])  # 처음 5개 샘플 출력\n",
    "            print(\"Softmax Probabilities:\", torch.softmax(outputs, dim=1)[:5])\n",
    "            break  # 한 번만 확인\n",
    "\n",
    "# ✅ 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 경로 설정\n",
    "    csv_path = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/OHT/oht_merged_output.csv\"\n",
    "    bin_root_folder = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/OHT\"\n",
    "    model_path = \"OHT/oht12_best_model.pth\"\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    img_dim_h, img_dim_w = 120, 160\n",
    "    batch_size = 16\n",
    "    num_classes = 4\n",
    "    features = [\n",
    "        \"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\",\n",
    "        \"CT1\", \"CT2\", \"CT3\", \"CT4\",\n",
    "        \"temp_max_value\", \"ex_temperature\",\n",
    "        \"ex_humidity\", \"ex_illuminance\"\n",
    "    ]\n",
    "\n",
    "    # ✅ 모델 및 데이터 로드\n",
    "    model = load_trained_model(model_path)\n",
    "    test_loader = load_test_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size)\n",
    "\n",
    "    # ✅ 테스트 평가\n",
    "    evaluate_model(model, test_loader, features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d6754-3b5e-4fbe-b485-166c08ba78a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7830c5b-50c5-483f-ba9b-445df020ccc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16b5f3-6f83-4ced-a6c3-27445f636a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f86d64-1a34-4ed5-98b4-80625d17e75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7520216-d8f3-45e7-8cbc-1d2774f3ec63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f173a0-ddd6-4935-ab4c-6e83686d59ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1: Train Loss = 0.3144, Train Accuracy = 87.20%, Val Loss = 0.2305, Val Accuracy = 91.19%, Time = 74.38s\n",
      "Epoch 2: Train Loss = 0.2168, Train Accuracy = 90.96%, Val Loss = 0.1705, Val Accuracy = 93.03%, Time = 74.61s\n",
      "Epoch 3: Train Loss = 0.1996, Train Accuracy = 91.52%, Val Loss = 0.1528, Val Accuracy = 94.38%, Time = 76.20s\n",
      "Epoch 4: Train Loss = 0.1937, Train Accuracy = 91.76%, Val Loss = 0.1784, Val Accuracy = 92.91%, Time = 85.01s\n",
      "Epoch 5: Train Loss = 0.1920, Train Accuracy = 91.77%, Val Loss = 0.1936, Val Accuracy = 93.27%, Time = 85.58s\n",
      "Epoch 6: Train Loss = 0.1711, Train Accuracy = 92.57%, Val Loss = 0.1442, Val Accuracy = 94.12%, Time = 78.23s\n",
      "Epoch 7: Train Loss = 0.1728, Train Accuracy = 92.52%, Val Loss = 0.1619, Val Accuracy = 94.42%, Time = 77.89s\n",
      "Epoch 8: Train Loss = 0.1722, Train Accuracy = 92.40%, Val Loss = 0.1967, Val Accuracy = 93.03%, Time = 73.74s\n",
      "Epoch 9: Train Loss = 0.1682, Train Accuracy = 92.59%, Val Loss = 0.1849, Val Accuracy = 93.59%, Time = 70.65s\n",
      "Epoch 10: Train Loss = 0.1691, Train Accuracy = 92.62%, Val Loss = 0.1755, Val Accuracy = 92.95%, Time = 77.75s\n",
      "Epoch 11: Train Loss = 0.1591, Train Accuracy = 92.87%, Val Loss = 0.1576, Val Accuracy = 94.12%, Time = 77.26s\n",
      "Epoch 12: Train Loss = 0.1566, Train Accuracy = 92.86%, Val Loss = 0.1918, Val Accuracy = 93.57%, Time = 74.25s\n",
      "Epoch 13: Train Loss = 0.1561, Train Accuracy = 92.92%, Val Loss = 0.1556, Val Accuracy = 94.22%, Time = 74.64s\n",
      "Early stopping at epoch 14\n",
      "Test Accuracy: 88.30%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# 1. 멀티모달 데이터셋 정의\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, csv_path, bin_root_folder, split_folder, img_dim_h, img_dim_w):\n",
    "        self.data = []\n",
    "        self.img_dim_h = img_dim_h\n",
    "        self.img_dim_w = img_dim_w\n",
    "\n",
    "        # 모든 BIN 파일의 경로 수집\n",
    "        bin_files = {}\n",
    "        split_path = os.path.join(bin_root_folder, split_folder)\n",
    "        for root, _, files in os.walk(split_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".bin\"):\n",
    "                    bin_files[file] = os.path.join(root, file)\n",
    "\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(csv_path)\n",
    "        #features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\", \"CT1\", \"CT2\", \"CT3\", \"CT4\", \"temp_max_value\"]\n",
    "        features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\", \"CT1\", \"CT2\", \"CT3\", \"CT4\", \"temp_max_value\", \"ex_temperature\", \"ex_humidity\", \"ex_illuminance\"]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            bin_filename = row['bin_filename']\n",
    "            if bin_filename in bin_files:\n",
    "                bin_path = bin_files[bin_filename]\n",
    "                try:\n",
    "                    img_data = np.load(bin_path).reshape((img_dim_h, img_dim_w))\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] BIN 파일 로드 실패: {bin_path}, {e}\")\n",
    "                    continue\n",
    "\n",
    "                aux_data = row[features].values.astype(np.float32)\n",
    "                label = int(row['state'])\n",
    "                self.data.append((img_data, aux_data, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data, aux_data, label = self.data[idx]\n",
    "        img_data = torch.tensor(img_data, dtype=torch.float32).unsqueeze(0)\n",
    "        aux_data = torch.tensor(aux_data, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img_data, aux_data, label\n",
    "\n",
    "\n",
    "# 2. 데이터 로더 함수\n",
    "def load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size=32):\n",
    "    train_dataset = MultimodalDataset(csv_path, bin_root_folder, 'train', img_dim_h, img_dim_w)\n",
    "    val_dataset = MultimodalDataset(csv_path, bin_root_folder, 'val', img_dim_h, img_dim_w)\n",
    "    test_dataset = MultimodalDataset(csv_path, bin_root_folder, 'test', img_dim_h, img_dim_w)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# 3. 모델 정의\n",
    "class ViTFeatureExtractor(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.vit = nn.Transformer(\n",
    "            d_model=embed_dim, nhead=num_heads, num_encoder_layers=depth,\n",
    "            batch_first=True, dropout=dropout_rate\n",
    "        )\n",
    "        self.patch_embed = nn.Conv2d(1, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        num_patches = (img_dim_h // patch_size) * (img_dim_w // patch_size)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches, embed_dim))\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = self.patch_embed(x).flatten(2).transpose(1, 2)\n",
    "        x = patches + self.pos_embedding\n",
    "        x = self.vit(x, x)\n",
    "        x = self.dropout(x.mean(dim=1))\n",
    "        return x\n",
    "\n",
    "\n",
    "class SoftLabelEncoder(nn.Module):\n",
    "    def __init__(self, aux_input_dim, embed_dim, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(aux_input_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, aux_data):\n",
    "        return self.fc(aux_data)\n",
    "\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, query, key):\n",
    "        attn_output, _ = self.attention(query, key, key)\n",
    "        return attn_output\n",
    "\n",
    "\n",
    "class ConditionClassifier(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, aux_input_dim, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.vit = ViTFeatureExtractor(img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate)\n",
    "        self.soft_label_encoder = SoftLabelEncoder(aux_input_dim, embed_dim, dropout_rate)\n",
    "        self.cross_attention = CrossAttention(embed_dim, num_heads)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, aux_data):\n",
    "        visual_features = self.vit(images)\n",
    "        aux_features = self.soft_label_encoder(aux_data)\n",
    "        visual_features = visual_features.unsqueeze(1)\n",
    "        aux_features = aux_features.unsqueeze(1)\n",
    "        integrated_features = self.cross_attention(visual_features, aux_features).squeeze(1)\n",
    "        return self.classifier(integrated_features)\n",
    "\n",
    "\n",
    "# 4. 학습 함수\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, num_epochs=30, patience=5):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for images, aux_data, labels in train_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, aux_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, aux_data, labels in val_loader:\n",
    "                images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "                outputs = model(images, aux_data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # ✅ 모델 전체 저장 방식으로 변경\n",
    "            torch.save(model, \"AGV/agv12_best_model.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        # Scheduler step\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {train_loss / len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy = {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss = {val_loss / len(val_loader):.4f}, \"\n",
    "              f\"Val Accuracy = {val_accuracy:.2f}%, \"\n",
    "              f\"Time = {end_time - start_time:.2f}s\")\n",
    "\n",
    "# 5. 실행\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV/agv_merged_output.csv\"\n",
    "    bin_root_folder = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV\"\n",
    "    img_dim_h, img_dim_w = 120, 160\n",
    "    aux_input_dim = 12\n",
    "    num_classes = 4\n",
    "    batch_size = 32\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_loader, val_loader, test_loader = load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 모델 정의\n",
    "    model = ConditionClassifier(\n",
    "        img_dim_h, img_dim_w, patch_size=16, embed_dim=128, num_heads=4,\n",
    "        depth=8, aux_input_dim=aux_input_dim, num_classes=num_classes, dropout_rate=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    # 학습\n",
    "    train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer,\n",
    "        scheduler, num_epochs=100, patience=8\n",
    "    )\n",
    "\n",
    "    # ✅ 모델 전체 로드 방식으로 변경\n",
    "    model = torch.load(\"AGV/agv12_best_model.pth\", map_location=device)\n",
    "    model.eval()\n",
    "\n",
    "    # 테스트\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eccc59-cc25-401c-962f-f5344c7294ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846243c0-be82-42be-aebc-a3987142017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#focal loss 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c485923f-7868-497d-aef6-875147614332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1: Train Loss = 0.0404, Train Accuracy = 82.52%, Val Loss = 0.0140, Val Accuracy = 91.81%, Time = 71.36s\n",
      "Epoch 2: Train Loss = 0.0203, Train Accuracy = 88.76%, Val Loss = 0.0130, Val Accuracy = 92.00%, Time = 72.58s\n",
      "Epoch 3: Train Loss = 0.0179, Train Accuracy = 89.60%, Val Loss = 0.0162, Val Accuracy = 90.60%, Time = 72.14s\n",
      "Epoch 4: Train Loss = 0.0170, Train Accuracy = 90.11%, Val Loss = 0.0178, Val Accuracy = 90.12%, Time = 74.04s\n",
      "Epoch 5: Train Loss = 0.0163, Train Accuracy = 90.27%, Val Loss = 0.0129, Val Accuracy = 93.19%, Time = 78.24s\n",
      "Epoch 6: Train Loss = 0.0143, Train Accuracy = 91.17%, Val Loss = 0.0148, Val Accuracy = 93.19%, Time = 77.85s\n",
      "Epoch 7: Train Loss = 0.0141, Train Accuracy = 91.28%, Val Loss = 0.0144, Val Accuracy = 92.76%, Time = 84.67s\n",
      "Epoch 8: Train Loss = 0.0138, Train Accuracy = 91.64%, Val Loss = 0.0117, Val Accuracy = 93.88%, Time = 74.11s\n",
      "Epoch 9: Train Loss = 0.0140, Train Accuracy = 91.31%, Val Loss = 0.0128, Val Accuracy = 93.09%, Time = 76.05s\n",
      "Epoch 10: Train Loss = 0.0139, Train Accuracy = 91.33%, Val Loss = 0.0144, Val Accuracy = 93.23%, Time = 70.35s\n",
      "Epoch 11: Train Loss = 0.0127, Train Accuracy = 92.09%, Val Loss = 0.0115, Val Accuracy = 94.42%, Time = 72.90s\n",
      "Epoch 12: Train Loss = 0.0126, Train Accuracy = 92.08%, Val Loss = 0.0113, Val Accuracy = 94.14%, Time = 70.30s\n",
      "Epoch 13: Train Loss = 0.0125, Train Accuracy = 92.01%, Val Loss = 0.0110, Val Accuracy = 94.08%, Time = 70.33s\n",
      "Epoch 14: Train Loss = 0.0126, Train Accuracy = 91.99%, Val Loss = 0.0121, Val Accuracy = 94.08%, Time = 70.39s\n",
      "Epoch 15: Train Loss = 0.0123, Train Accuracy = 92.29%, Val Loss = 0.0109, Val Accuracy = 93.88%, Time = 70.66s\n",
      "Epoch 16: Train Loss = 0.0120, Train Accuracy = 92.17%, Val Loss = 0.0112, Val Accuracy = 93.76%, Time = 70.42s\n",
      "Epoch 17: Train Loss = 0.0120, Train Accuracy = 92.26%, Val Loss = 0.0126, Val Accuracy = 94.06%, Time = 72.53s\n",
      "Epoch 18: Train Loss = 0.0119, Train Accuracy = 92.22%, Val Loss = 0.0121, Val Accuracy = 94.10%, Time = 72.74s\n",
      "Epoch 19: Train Loss = 0.0117, Train Accuracy = 92.45%, Val Loss = 0.0136, Val Accuracy = 93.65%, Time = 72.72s\n",
      "Epoch 20: Train Loss = 0.0118, Train Accuracy = 92.34%, Val Loss = 0.0123, Val Accuracy = 94.14%, Time = 79.70s\n",
      "Epoch 21: Train Loss = 0.0116, Train Accuracy = 92.49%, Val Loss = 0.0122, Val Accuracy = 94.12%, Time = 72.77s\n",
      "Epoch 22: Train Loss = 0.0117, Train Accuracy = 92.43%, Val Loss = 0.0133, Val Accuracy = 93.92%, Time = 72.81s\n",
      "Early stopping at epoch 23\n",
      "Test Accuracy: 88.58%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. 멀티모달 데이터셋 정의\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, csv_path, bin_root_folder, split_folder, img_dim_h, img_dim_w):\n",
    "        self.data = []\n",
    "        self.img_dim_h = img_dim_h\n",
    "        self.img_dim_w = img_dim_w\n",
    "\n",
    "        # 모든 BIN 파일의 경로 수집\n",
    "        bin_files = {}\n",
    "        split_path = os.path.join(bin_root_folder, split_folder)\n",
    "        for root, _, files in os.walk(split_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".bin\"):\n",
    "                    bin_files[file] = os.path.join(root, file)\n",
    "\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(csv_path)\n",
    "        #features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\", \"CT1\", \"CT2\", \"CT3\", \"CT4\", \"temp_max_value\"]\n",
    "        features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\", \"CT1\", \"CT2\", \"CT3\", \"CT4\", \"temp_max_value\", \"ex_temperature\", \"ex_humidity\", \"ex_illuminance\"]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            bin_filename = row['bin_filename']\n",
    "            if bin_filename in bin_files:\n",
    "                bin_path = bin_files[bin_filename]\n",
    "                try:\n",
    "                    img_data = np.load(bin_path).reshape((img_dim_h, img_dim_w))\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] BIN 파일 로드 실패: {bin_path}, {e}\")\n",
    "                    continue\n",
    "\n",
    "                aux_data = row[features].values.astype(np.float32)\n",
    "                label = int(row['state'])\n",
    "                self.data.append((img_data, aux_data, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data, aux_data, label = self.data[idx]\n",
    "        img_data = torch.tensor(img_data, dtype=torch.float32).unsqueeze(0)\n",
    "        aux_data = torch.tensor(aux_data, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img_data, aux_data, label\n",
    "\n",
    "\n",
    "# 2. 데이터 로더 함수\n",
    "def load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size=32):\n",
    "    train_dataset = MultimodalDataset(csv_path, bin_root_folder, 'train', img_dim_h, img_dim_w)\n",
    "    val_dataset = MultimodalDataset(csv_path, bin_root_folder, 'val', img_dim_h, img_dim_w)\n",
    "    test_dataset = MultimodalDataset(csv_path, bin_root_folder, 'test', img_dim_h, img_dim_w)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# 3. 모델 정의\n",
    "class ViTFeatureExtractor(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.vit = nn.Transformer(\n",
    "            d_model=embed_dim, nhead=num_heads, num_encoder_layers=depth,\n",
    "            batch_first=True, dropout=dropout_rate\n",
    "        )\n",
    "        self.patch_embed = nn.Conv2d(1, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        num_patches = (img_dim_h // patch_size) * (img_dim_w // patch_size)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches, embed_dim))\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = self.patch_embed(x).flatten(2).transpose(1, 2)\n",
    "        x = patches + self.pos_embedding\n",
    "        x = self.vit(x, x)\n",
    "        x = self.dropout(x.mean(dim=1))\n",
    "        return x\n",
    "\n",
    "\n",
    "class SoftLabelEncoder(nn.Module):\n",
    "    def __init__(self, aux_input_dim, embed_dim, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(aux_input_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, aux_data):\n",
    "        return self.fc(aux_data)\n",
    "\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, query, key):\n",
    "        attn_output, _ = self.attention(query, key, key)\n",
    "        return attn_output\n",
    "\n",
    "\n",
    "class ConditionClassifier(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, aux_input_dim, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.vit = ViTFeatureExtractor(img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate)\n",
    "        self.soft_label_encoder = SoftLabelEncoder(aux_input_dim, embed_dim, dropout_rate)\n",
    "        self.cross_attention = CrossAttention(embed_dim, num_heads)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, aux_data):\n",
    "        visual_features = self.vit(images)\n",
    "        aux_features = self.soft_label_encoder(aux_data)\n",
    "        visual_features = visual_features.unsqueeze(1)\n",
    "        aux_features = aux_features.unsqueeze(1)\n",
    "        integrated_features = self.cross_attention(visual_features, aux_features).squeeze(1)\n",
    "        return self.classifier(integrated_features)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        \"\"\"\n",
    "        gamma: 어려운 샘플에 대한 가중치 조절 파라미터. (기본값: 2.0)\n",
    "        alpha: 클래스별 가중치. 스칼라 또는 텐서로 지정할 수 있음.\n",
    "        reduction: 'mean' 또는 'sum'으로 출력 손실을 집계하는 방식.\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs: (batch_size, num_classes)\n",
    "        # targets: (batch_size) - 각 원소는 0 ~ num_classes-1 사이의 정수\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)  # p_t = exp(-cross_entropy)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        # alpha가 지정된 경우, 각 샘플에 대한 가중치를 곱해줌\n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (float, int)):\n",
    "                alpha_factor = self.alpha\n",
    "            elif isinstance(self.alpha, torch.Tensor):\n",
    "                alpha_factor = self.alpha[targets]\n",
    "            else:\n",
    "                raise TypeError(\"alpha must be float, int, or torch.Tensor\")\n",
    "            focal_loss = alpha_factor * focal_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "# 4. 학습 함수\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, num_epochs=30, patience=5):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for images, aux_data, labels in train_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, aux_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, aux_data, labels in val_loader:\n",
    "                images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "                outputs = model(images, aux_data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            # ✅ 모델 전체 저장 방식으로 변경\n",
    "            torch.save(model, \"AGV/agv12_best_model.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        # Scheduler step\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {train_loss / len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy = {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss = {val_loss / len(val_loader):.4f}, \"\n",
    "              f\"Val Accuracy = {val_accuracy:.2f}%, \"\n",
    "              f\"Time = {end_time - start_time:.2f}s\")\n",
    "\n",
    "# 5. 실행\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV/agv_merged_output.csv\"\n",
    "    bin_root_folder = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV\"\n",
    "    img_dim_h, img_dim_w = 120, 160\n",
    "    aux_input_dim = 12\n",
    "    num_classes = 4\n",
    "    batch_size = 32\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_loader, val_loader, test_loader = load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # 모델 정의\n",
    "    model = ConditionClassifier(\n",
    "        img_dim_h, img_dim_w, patch_size=16, embed_dim=128, num_heads=4,\n",
    "        depth=8, aux_input_dim=aux_input_dim, num_classes=num_classes, dropout_rate=0.5\n",
    "    ).to(device)\n",
    "\n",
    "    # 기존 CrossEntropyLoss 대신 Focal Loss 사용\n",
    "    criterion = FocalLoss(gamma=2.0, alpha=0.25, reduction='mean')\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    # 학습\n",
    "    train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer,\n",
    "        scheduler, num_epochs=100, patience=8\n",
    "    )\n",
    "\n",
    "    # 최적 모델 로드 및 평가\n",
    "    model = torch.load(\"AGV/agv12_best_model.pth\", map_location=device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45826a9d-82f8-4250-84a4-7d1bf04aec5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10c0e16-77e6-4899-b7b2-afe697584ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1: Train Loss = 0.0224, Train Accuracy = 88.36%, Val Loss = 0.0130, Val Accuracy = 92.22%, Time = 71.88s\n",
      "Epoch 2: Train Loss = 0.0142, Train Accuracy = 91.14%, Val Loss = 0.0128, Val Accuracy = 92.10%, Time = 68.86s\n",
      "Epoch 3: Train Loss = 0.0135, Train Accuracy = 91.32%, Val Loss = 0.0122, Val Accuracy = 92.76%, Time = 69.10s\n",
      "Epoch 4: Train Loss = 0.0134, Train Accuracy = 91.34%, Val Loss = 0.0129, Val Accuracy = 92.60%, Time = 69.04s\n",
      "Epoch 5: Train Loss = 0.0129, Train Accuracy = 91.53%, Val Loss = 0.0133, Val Accuracy = 93.43%, Time = 69.61s\n",
      "Epoch 6: Train Loss = 0.0117, Train Accuracy = 92.35%, Val Loss = 0.0147, Val Accuracy = 94.18%, Time = 70.03s\n",
      "Epoch 7: Train Loss = 0.0114, Train Accuracy = 92.41%, Val Loss = 0.0116, Val Accuracy = 93.98%, Time = 71.50s\n",
      "Epoch 8: Train Loss = 0.0114, Train Accuracy = 92.55%, Val Loss = 0.0102, Val Accuracy = 94.93%, Time = 74.44s\n",
      "Epoch 9: Train Loss = 0.0114, Train Accuracy = 92.41%, Val Loss = 0.0134, Val Accuracy = 93.15%, Time = 75.29s\n",
      "Epoch 10: Train Loss = 0.0111, Train Accuracy = 92.59%, Val Loss = 0.0121, Val Accuracy = 94.66%, Time = 76.69s\n",
      "Epoch 11: Train Loss = 0.0106, Train Accuracy = 92.85%, Val Loss = 0.0111, Val Accuracy = 94.66%, Time = 79.04s\n",
      "Epoch 12: Train Loss = 0.0106, Train Accuracy = 92.84%, Val Loss = 0.0120, Val Accuracy = 94.24%, Time = 87.93s\n",
      "Epoch 13: Train Loss = 0.0105, Train Accuracy = 92.83%, Val Loss = 0.0144, Val Accuracy = 93.61%, Time = 89.33s\n",
      "Epoch 14: Train Loss = 0.0104, Train Accuracy = 92.97%, Val Loss = 0.0159, Val Accuracy = 93.80%, Time = 90.54s\n",
      "Epoch 15: Train Loss = 0.0104, Train Accuracy = 92.95%, Val Loss = 0.0138, Val Accuracy = 94.58%, Time = 92.34s\n",
      "Early stopping at epoch 16\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AGV/agv12_best_model_0207.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31844\\4203920650.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    274\u001b[0m     )\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AGV/agv12_best_model_0207.pth\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AGV/agv12_best_model_0207.pth'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. 멀티모달 데이터셋 정의\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, csv_path, bin_root_folder, split_folder, img_dim_h, img_dim_w):\n",
    "        self.data = []\n",
    "        self.img_dim_h = img_dim_h\n",
    "        self.img_dim_w = img_dim_w\n",
    "\n",
    "        # 모든 BIN 파일의 경로 수집\n",
    "        bin_files = {}\n",
    "        split_path = os.path.join(bin_root_folder, split_folder)\n",
    "        for root, _, files in os.walk(split_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".bin\"):\n",
    "                    bin_files[file] = os.path.join(root, file)\n",
    "\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(csv_path)\n",
    "        features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\", \"CT1\", \"CT2\", \"CT3\", \"CT4\", \n",
    "                    \"temp_max_value\", \"ex_temperature\", \"ex_humidity\", \"ex_illuminance\"]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            bin_filename = row['bin_filename']\n",
    "            if bin_filename in bin_files:\n",
    "                bin_path = bin_files[bin_filename]\n",
    "                try:\n",
    "                    img_data = np.load(bin_path).reshape((img_dim_h, img_dim_w))\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] BIN 파일 로드 실패: {bin_path}, {e}\")\n",
    "                    continue\n",
    "\n",
    "                aux_data = row[features].values.astype(np.float32)\n",
    "                label = int(row['state'])\n",
    "                self.data.append((img_data, aux_data, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data, aux_data, label = self.data[idx]\n",
    "        img_data = torch.tensor(img_data, dtype=torch.float32).unsqueeze(0)\n",
    "        aux_data = torch.tensor(aux_data, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img_data, aux_data, label\n",
    "\n",
    "\n",
    "# 2. 데이터 로더 함수\n",
    "def load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size=32):\n",
    "    train_dataset = MultimodalDataset(csv_path, bin_root_folder, 'train', img_dim_h, img_dim_w)\n",
    "    val_dataset = MultimodalDataset(csv_path, bin_root_folder, 'val', img_dim_h, img_dim_w)\n",
    "    test_dataset = MultimodalDataset(csv_path, bin_root_folder, 'test', img_dim_h, img_dim_w)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# 3. 모델 정의\n",
    "\n",
    "class ViTFeatureExtractor(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.patch_embed = nn.Conv2d(1, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        num_patches = (img_dim_h // patch_size) * (img_dim_w // patch_size)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches, embed_dim))\n",
    "        # LayerNorm 적용: 패치 임베딩 후\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.vit = nn.Transformer(\n",
    "            d_model=embed_dim, nhead=num_heads, num_encoder_layers=depth,\n",
    "            batch_first=True, dropout=dropout_rate\n",
    "        )\n",
    "        # LayerNorm 적용: Transformer 출력 후 (시퀀스 평균 전)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = self.patch_embed(x).flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)\n",
    "        patches = self.norm1(patches)\n",
    "        x = patches + self.pos_embedding\n",
    "        x = self.vit(x, x)  # Transformer 인코더\n",
    "        # 시퀀스 차원에 대해 평균을 취한 후 정규화\n",
    "        x = self.norm2(x.mean(dim=1))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SoftLabelEncoder(nn.Module):\n",
    "    def __init__(self, aux_input_dim, embed_dim, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(aux_input_dim, embed_dim),\n",
    "            nn.LayerNorm(embed_dim),  # 정규화 추가\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.LayerNorm(embed_dim)   # 정규화 추가\n",
    "        )\n",
    "\n",
    "    def forward(self, aux_data):\n",
    "        return self.fc(aux_data)\n",
    "\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(embed_dim)  # 어텐션 결과 후 정규화\n",
    "\n",
    "    def forward(self, query, key):\n",
    "        attn_output, _ = self.attention(query, key, key)\n",
    "        # Residual 연결 후 정규화\n",
    "        out = self.norm(query + attn_output)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ConditionClassifier(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, aux_input_dim, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.vit = ViTFeatureExtractor(img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate)\n",
    "        self.soft_label_encoder = SoftLabelEncoder(aux_input_dim, embed_dim, dropout_rate)\n",
    "        self.cross_attention = CrossAttention(embed_dim, num_heads)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, aux_data):\n",
    "        visual_features = self.vit(images)              # (B, embed_dim)\n",
    "        aux_features = self.soft_label_encoder(aux_data)   # (B, embed_dim)\n",
    "        visual_features = visual_features.unsqueeze(1)     # (B, 1, embed_dim)\n",
    "        aux_features = aux_features.unsqueeze(1)           # (B, 1, embed_dim)\n",
    "        integrated_features = self.cross_attention(visual_features, aux_features).squeeze(1)\n",
    "        return self.classifier(integrated_features)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        \"\"\"\n",
    "        gamma: 어려운 샘플에 대한 가중치 조절 파라미터 (기본값: 2.0)\n",
    "        alpha: 클래스별 가중치 (스칼라 또는 텐서)\n",
    "        reduction: 'mean' 또는 'sum' 방식으로 집계\n",
    "        \"\"\"\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (float, int)):\n",
    "                alpha_factor = self.alpha\n",
    "            elif isinstance(self.alpha, torch.Tensor):\n",
    "                alpha_factor = self.alpha[targets]\n",
    "            else:\n",
    "                raise TypeError(\"alpha must be float, int, or torch.Tensor\")\n",
    "            focal_loss = alpha_factor * focal_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "# 4. 학습 함수\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, num_epochs=30, patience=5):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Training\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for images, aux_data, labels in train_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, aux_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, aux_data, labels in val_loader:\n",
    "                images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "                outputs = model(images, aux_data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Early Stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model, \"AGV/agv12_best_model_0207.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {train_loss / len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy = {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss = {val_loss / len(val_loader):.4f}, \"\n",
    "              f\"Val Accuracy = {val_accuracy:.2f}%, \"\n",
    "              f\"Time = {end_time - start_time:.2f}s\")\n",
    "\n",
    "# 5. 실행\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV/agv_merged_output.csv\"\n",
    "    bin_root_folder = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV\"\n",
    "    img_dim_h, img_dim_w = 120, 160\n",
    "    aux_input_dim = 12\n",
    "    num_classes = 4\n",
    "    batch_size = 32\n",
    "\n",
    "    train_loader, val_loader, test_loader = load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = ConditionClassifier(\n",
    "        img_dim_h, img_dim_w, patch_size=16, embed_dim=128, num_heads=4,\n",
    "        depth=8, aux_input_dim=aux_input_dim, num_classes=num_classes, dropout_rate=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    # Focal Loss 사용\n",
    "    criterion = FocalLoss(gamma=2.0, alpha=0.25, reduction='mean')\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer,\n",
    "        scheduler, num_epochs=100, patience=8\n",
    "    )\n",
    "\n",
    "    model = torch.load(\"AGV/agv12_best_model_0207.pth\", map_location=device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307cb27-2480-4bbd-bd72-c37f5e40ee8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff45acee-487c-4e2b-90cb-b1b874768daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross attention 대신 gated fusion 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2474a4f-58e6-4595-8a44-71de6e45348c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1: Train Loss = 0.0224, Train Accuracy = 88.77%, Val Loss = 0.0136, Val Accuracy = 92.60%, Time = 75.64s\n",
      "Epoch 2: Train Loss = 0.0134, Train Accuracy = 91.46%, Val Loss = 0.0134, Val Accuracy = 93.15%, Time = 75.49s\n",
      "Epoch 3: Train Loss = 0.0128, Train Accuracy = 91.79%, Val Loss = 0.0101, Val Accuracy = 94.12%, Time = 75.63s\n",
      "Epoch 4: Train Loss = 0.0124, Train Accuracy = 91.93%, Val Loss = 0.0121, Val Accuracy = 93.09%, Time = 76.21s\n",
      "Epoch 5: Train Loss = 0.0122, Train Accuracy = 92.07%, Val Loss = 0.0112, Val Accuracy = 94.28%, Time = 75.97s\n",
      "Epoch 6: Train Loss = 0.0112, Train Accuracy = 92.66%, Val Loss = 0.0119, Val Accuracy = 94.38%, Time = 76.11s\n",
      "Epoch 7: Train Loss = 0.0110, Train Accuracy = 92.73%, Val Loss = 0.0118, Val Accuracy = 93.92%, Time = 75.86s\n",
      "Epoch 8: Train Loss = 0.0110, Train Accuracy = 92.64%, Val Loss = 0.0117, Val Accuracy = 94.34%, Time = 76.24s\n",
      "Epoch 9: Train Loss = 0.0107, Train Accuracy = 92.62%, Val Loss = 0.0130, Val Accuracy = 94.18%, Time = 75.91s\n",
      "Epoch 10: Train Loss = 0.0107, Train Accuracy = 92.61%, Val Loss = 0.0135, Val Accuracy = 93.96%, Time = 75.83s\n",
      "Early stopping at epoch 11\n",
      "Test Accuracy: 89.23%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. 멀티모달 데이터셋 정의\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, csv_path, bin_root_folder, split_folder, img_dim_h, img_dim_w):\n",
    "        self.data = []\n",
    "        self.img_dim_h = img_dim_h\n",
    "        self.img_dim_w = img_dim_w\n",
    "\n",
    "        # 모든 BIN 파일의 경로 수집\n",
    "        bin_files = {}\n",
    "        split_path = os.path.join(bin_root_folder, split_folder)\n",
    "        for root, _, files in os.walk(split_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".bin\"):\n",
    "                    bin_files[file] = os.path.join(root, file)\n",
    "\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(csv_path)\n",
    "        features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\", \"CT1\", \"CT2\", \"CT3\", \"CT4\", \n",
    "                    \"temp_max_value\", \"ex_temperature\", \"ex_humidity\", \"ex_illuminance\"]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            bin_filename = row['bin_filename']\n",
    "            if bin_filename in bin_files:\n",
    "                bin_path = bin_files[bin_filename]\n",
    "                try:\n",
    "                    img_data = np.load(bin_path).reshape((img_dim_h, img_dim_w))\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] BIN 파일 로드 실패: {bin_path}, {e}\")\n",
    "                    continue\n",
    "\n",
    "                aux_data = row[features].values.astype(np.float32)\n",
    "                label = int(row['state'])\n",
    "                self.data.append((img_data, aux_data, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data, aux_data, label = self.data[idx]\n",
    "        img_data = torch.tensor(img_data, dtype=torch.float32).unsqueeze(0)\n",
    "        aux_data = torch.tensor(aux_data, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img_data, aux_data, label\n",
    "\n",
    "\n",
    "# 2. 데이터 로더 함수\n",
    "def load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size=32):\n",
    "    train_dataset = MultimodalDataset(csv_path, bin_root_folder, 'train', img_dim_h, img_dim_w)\n",
    "    val_dataset = MultimodalDataset(csv_path, bin_root_folder, 'val', img_dim_h, img_dim_w)\n",
    "    test_dataset = MultimodalDataset(csv_path, bin_root_folder, 'test', img_dim_h, img_dim_w)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# 3. 모델 정의\n",
    "\n",
    "# (1) 이미지 특징 추출 및 정규화: ViTFeatureExtractor\n",
    "class ViTFeatureExtractor(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.patch_embed = nn.Conv2d(1, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        num_patches = (img_dim_h // patch_size) * (img_dim_w // patch_size)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches, embed_dim))\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)  # 패치 임베딩 후 정규화\n",
    "        self.vit = nn.Transformer(\n",
    "            d_model=embed_dim, nhead=num_heads, num_encoder_layers=depth,\n",
    "            batch_first=True, dropout=dropout_rate\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)  # Transformer 출력 후 정규화\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = self.patch_embed(x).flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)\n",
    "        patches = self.norm1(patches)\n",
    "        x = patches + self.pos_embedding\n",
    "        x = self.vit(x, x)\n",
    "        x = self.norm2(x.mean(dim=1))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# (2) 보조 데이터 임베딩: SoftLabelEncoder\n",
    "class SoftLabelEncoder(nn.Module):\n",
    "    def __init__(self, aux_input_dim, embed_dim, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(aux_input_dim, embed_dim),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.LayerNorm(embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, aux_data):\n",
    "        return self.fc(aux_data)\n",
    "\n",
    "\n",
    "# (3) 멀티모달 피처 융합을 위한 Gated Fusion 모듈\n",
    "class GatedFusion(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        # 두 모달리티의 임베딩을 연결하여 게이트 값을 산출 (값은 0~1 사이로 조정)\n",
    "        self.fc_gate = nn.Linear(embed_dim * 2, embed_dim)\n",
    "        \n",
    "    def forward(self, visual, aux):\n",
    "        # visual, aux: (B, embed_dim)\n",
    "        combined = torch.cat([visual, aux], dim=1)  # (B, 2*embed_dim)\n",
    "        gate = torch.sigmoid(self.fc_gate(combined)) # (B, embed_dim)\n",
    "        # gate를 통해 visual과 aux의 기여도를 조절하여 융합\n",
    "        fused = gate * visual + (1 - gate) * aux\n",
    "        return fused\n",
    "\n",
    "\n",
    "# (4) 최종 분류기: ConditionClassifier (Gated Fusion 적용)\n",
    "class ConditionClassifier(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, aux_input_dim, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.vit = ViTFeatureExtractor(img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate)\n",
    "        self.soft_label_encoder = SoftLabelEncoder(aux_input_dim, embed_dim, dropout_rate)\n",
    "        # 기존 CrossAttention 대신 GatedFusion 모듈 사용\n",
    "        self.gated_fusion = GatedFusion(embed_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, aux_data):\n",
    "        visual_features = self.vit(images)              # (B, embed_dim)\n",
    "        aux_features = self.soft_label_encoder(aux_data)   # (B, embed_dim)\n",
    "        fused_features = self.gated_fusion(visual_features, aux_features)  # (B, embed_dim)\n",
    "        return self.classifier(fused_features)\n",
    "\n",
    "\n",
    "# (5) Focal Loss (기존 코드와 동일)\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (float, int)):\n",
    "                alpha_factor = self.alpha\n",
    "            elif isinstance(self.alpha, torch.Tensor):\n",
    "                alpha_factor = self.alpha[targets]\n",
    "            else:\n",
    "                raise TypeError(\"alpha must be float, int, or torch.Tensor\")\n",
    "            focal_loss = alpha_factor * focal_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "# 4. 학습 함수\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, num_epochs=30, patience=5):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for images, aux_data, labels in train_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, aux_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, aux_data, labels in val_loader:\n",
    "                images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "                outputs = model(images, aux_data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model, \"AGV/agv12_best_model.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {train_loss / len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy = {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss = {val_loss / len(val_loader):.4f}, \"\n",
    "              f\"Val Accuracy = {val_accuracy:.2f}%, \"\n",
    "              f\"Time = {end_time - start_time:.2f}s\")\n",
    "\n",
    "# 5. 실행\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV/agv_merged_output.csv\"\n",
    "    bin_root_folder = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV\"\n",
    "    img_dim_h, img_dim_w = 120, 160\n",
    "    aux_input_dim = 12\n",
    "    num_classes = 4\n",
    "    batch_size = 32\n",
    "\n",
    "    train_loader, val_loader, test_loader = load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = ConditionClassifier(\n",
    "        img_dim_h, img_dim_w, patch_size=16, embed_dim=128, num_heads=4,\n",
    "        depth=8, aux_input_dim=aux_input_dim, num_classes=num_classes, dropout_rate=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = FocalLoss(gamma=2.0, alpha=0.25, reduction='mean')\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer,\n",
    "        scheduler, num_epochs=100, patience=8\n",
    "    )\n",
    "\n",
    "    model = torch.load(\"AGV/agv12_best_model.pth\", map_location=device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d0d7a-03c4-4af6-a1ba-6c23cf5a229d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41fc9f57-0b61-446e-870b-58d8517dfb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1: Train Loss = 0.0227, Train Accuracy = 88.49%, Val Loss = 0.0120, Val Accuracy = 93.73%, Time = 71.11s\n",
      "Epoch 2: Train Loss = 0.0133, Train Accuracy = 91.43%, Val Loss = 0.0115, Val Accuracy = 93.23%, Time = 70.92s\n",
      "Epoch 3: Train Loss = 0.0130, Train Accuracy = 91.78%, Val Loss = 0.0104, Val Accuracy = 94.20%, Time = 71.69s\n",
      "Epoch 4: Train Loss = 0.0124, Train Accuracy = 91.99%, Val Loss = 0.0109, Val Accuracy = 93.53%, Time = 71.06s\n",
      "Epoch 5: Train Loss = 0.0120, Train Accuracy = 92.15%, Val Loss = 0.0109, Val Accuracy = 93.25%, Time = 71.00s\n",
      "Epoch 6: Train Loss = 0.0112, Train Accuracy = 92.56%, Val Loss = 0.0093, Val Accuracy = 94.24%, Time = 71.04s\n",
      "Epoch 7: Train Loss = 0.0110, Train Accuracy = 92.69%, Val Loss = 0.0103, Val Accuracy = 94.40%, Time = 71.60s\n",
      "Epoch 8: Train Loss = 0.0109, Train Accuracy = 92.74%, Val Loss = 0.0107, Val Accuracy = 94.44%, Time = 71.58s\n",
      "Epoch 9: Train Loss = 0.0109, Train Accuracy = 92.73%, Val Loss = 0.0095, Val Accuracy = 94.24%, Time = 71.90s\n",
      "Epoch 10: Train Loss = 0.0108, Train Accuracy = 92.66%, Val Loss = 0.0108, Val Accuracy = 94.20%, Time = 72.30s\n",
      "Epoch 11: Train Loss = 0.0104, Train Accuracy = 92.85%, Val Loss = 0.0102, Val Accuracy = 94.66%, Time = 72.30s\n",
      "Epoch 12: Train Loss = 0.0102, Train Accuracy = 93.03%, Val Loss = 0.0108, Val Accuracy = 94.44%, Time = 72.26s\n",
      "Epoch 13: Train Loss = 0.0101, Train Accuracy = 93.10%, Val Loss = 0.0121, Val Accuracy = 93.88%, Time = 72.55s\n",
      "Early stopping at epoch 14\n",
      "Test Accuracy: 88.48%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. 멀티모달 데이터셋 정의\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, csv_path, bin_root_folder, split_folder, img_dim_h, img_dim_w):\n",
    "        self.data = []\n",
    "        self.img_dim_h = img_dim_h\n",
    "        self.img_dim_w = img_dim_w\n",
    "\n",
    "        # 모든 BIN 파일의 경로 수집\n",
    "        bin_files = {}\n",
    "        split_path = os.path.join(bin_root_folder, split_folder)\n",
    "        for root, _, files in os.walk(split_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".bin\"):\n",
    "                    bin_files[file] = os.path.join(root, file)\n",
    "\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(csv_path)\n",
    "        features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\", \"CT1\", \"CT2\", \"CT3\", \"CT4\", \n",
    "                    \"temp_max_value\", \"ex_temperature\", \"ex_humidity\", \"ex_illuminance\"]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            bin_filename = row['bin_filename']\n",
    "            if bin_filename in bin_files:\n",
    "                bin_path = bin_files[bin_filename]\n",
    "                try:\n",
    "                    img_data = np.load(bin_path).reshape((img_dim_h, img_dim_w))\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] BIN 파일 로드 실패: {bin_path}, {e}\")\n",
    "                    continue\n",
    "\n",
    "                aux_data = row[features].values.astype(np.float32)\n",
    "                label = int(row['state'])\n",
    "                self.data.append((img_data, aux_data, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data, aux_data, label = self.data[idx]\n",
    "        img_data = torch.tensor(img_data, dtype=torch.float32).unsqueeze(0)\n",
    "        aux_data = torch.tensor(aux_data, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img_data, aux_data, label\n",
    "\n",
    "\n",
    "# 2. 데이터 로더 함수\n",
    "def load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size=32):\n",
    "    train_dataset = MultimodalDataset(csv_path, bin_root_folder, 'train', img_dim_h, img_dim_w)\n",
    "    val_dataset = MultimodalDataset(csv_path, bin_root_folder, 'val', img_dim_h, img_dim_w)\n",
    "    test_dataset = MultimodalDataset(csv_path, bin_root_folder, 'test', img_dim_h, img_dim_w)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# 3. 모델 정의\n",
    "\n",
    "# (1) 이미지 특징 추출 및 정규화: ViTFeatureExtractor\n",
    "class ViTFeatureExtractor(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.patch_embed = nn.Conv2d(1, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        num_patches = (img_dim_h // patch_size) * (img_dim_w // patch_size)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches, embed_dim))\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)  # 패치 임베딩 후 정규화\n",
    "        self.vit = nn.Transformer(\n",
    "            d_model=embed_dim, nhead=num_heads, num_encoder_layers=depth,\n",
    "            batch_first=True, dropout=dropout_rate\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)  # Transformer 출력 후 정규화\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        patches = self.patch_embed(x).flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)\n",
    "        patches = self.norm1(patches)\n",
    "        x = patches + self.pos_embedding\n",
    "        x = self.vit(x, x)\n",
    "        x = self.norm2(x.mean(dim=1))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# (2) 보조 데이터 임베딩: SoftLabelEncoder\n",
    "class SoftLabelEncoder(nn.Module):\n",
    "    def __init__(self, aux_input_dim, embed_dim, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(aux_input_dim, embed_dim),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.LayerNorm(embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, aux_data):\n",
    "        return self.fc(aux_data)\n",
    "\n",
    "\n",
    "# (3') 멀티모달 피처 융합을 위한 Bilinear Fusion 모듈\n",
    "class BilinearFusion(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        # 곱셈한 결과를 재투영할 선형 계층\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, visual, aux):\n",
    "        # visual, aux: (B, embed_dim)\n",
    "        # Element-wise 곱셈을 통해 두 모달리티의 상호작용을 캡처\n",
    "        fused = visual * aux  # (B, embed_dim)\n",
    "        fused = self.relu(self.fc(fused))\n",
    "        return fused\n",
    "\n",
    "\n",
    "# (4') 최종 분류기: ConditionClassifier - Bilinear Fusion 적용\n",
    "class ConditionClassifierBilinear(nn.Module):\n",
    "    def __init__(self, img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, aux_input_dim, num_classes, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.vit = ViTFeatureExtractor(img_dim_h, img_dim_w, patch_size, embed_dim, num_heads, depth, dropout_rate)\n",
    "        self.soft_label_encoder = SoftLabelEncoder(aux_input_dim, embed_dim, dropout_rate)\n",
    "        # Gated Fusion 대신 Bilinear Fusion 사용\n",
    "        self.bilinear_fusion = BilinearFusion(embed_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(embed_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, images, aux_data):\n",
    "        visual_features = self.vit(images)              # (B, embed_dim)\n",
    "        aux_features = self.soft_label_encoder(aux_data)   # (B, embed_dim)\n",
    "        fused_features = self.bilinear_fusion(visual_features, aux_features)  # (B, embed_dim)\n",
    "        return self.classifier(fused_features)\n",
    "\n",
    "\n",
    "\n",
    "# (5) Focal Loss (기존 코드와 동일)\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (float, int)):\n",
    "                alpha_factor = self.alpha\n",
    "            elif isinstance(self.alpha, torch.Tensor):\n",
    "                alpha_factor = self.alpha[targets]\n",
    "            else:\n",
    "                raise TypeError(\"alpha must be float, int, or torch.Tensor\")\n",
    "            focal_loss = alpha_factor * focal_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "# 4. 학습 함수\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler=None, num_epochs=30, patience=5):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for images, aux_data, labels in train_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, aux_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, aux_data, labels in val_loader:\n",
    "                images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "                outputs = model(images, aux_data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model, \"AGV/agv12_best_model.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Train Loss = {train_loss / len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy = {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss = {val_loss / len(val_loader):.4f}, \"\n",
    "              f\"Val Accuracy = {val_accuracy:.2f}%, \"\n",
    "              f\"Time = {end_time - start_time:.2f}s\")\n",
    "\n",
    "# 5. 실행\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV/agv_merged_output.csv\"\n",
    "    bin_root_folder = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV\"\n",
    "    img_dim_h, img_dim_w = 120, 160\n",
    "    aux_input_dim = 12\n",
    "    num_classes = 4\n",
    "    batch_size = 32\n",
    "\n",
    "    train_loader, val_loader, test_loader = load_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = ConditionClassifier(\n",
    "        img_dim_h, img_dim_w, patch_size=16, embed_dim=128, num_heads=4,\n",
    "        depth=8, aux_input_dim=aux_input_dim, num_classes=num_classes, dropout_rate=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = FocalLoss(gamma=2.0, alpha=0.25, reduction='mean')\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer,\n",
    "        scheduler, num_epochs=100, patience=8\n",
    "    )\n",
    "\n",
    "    model = torch.load(\"AGV/agv12_best_model.pth\", map_location=device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c96aaab-0999-4e57-9282-7b7cf6b5dc00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7984a1-f267-4583-83b0-6c178f8e261d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d721778-72fe-4f4e-915f-e802e2fd37e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a65b6-bced-4b5e-8844-92bcf153af8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326077af-0621-4ec1-9fd8-9cd40792e973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "모델 불러오기 완료\n",
      "\n",
      "📊 Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9328    0.9180    0.9253      2584\n",
      "           1     0.8701    0.8006    0.8339      1088\n",
      "           2     0.8658    0.8848    0.8752      1050\n",
      "           3     0.7425    0.9788    0.8444       330\n",
      "\n",
      "    accuracy                         0.8897      5052\n",
      "   macro avg     0.8528    0.8955    0.8697      5052\n",
      "weighted avg     0.8929    0.8897    0.8899      5052\n",
      "\n",
      "Predicted Class Distribution: {0: 2543, 1: 1001, 2: 1073, 3: 435}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Feature Statistics\n",
      "\n",
      "[각 클래스별 평균값]\n",
      "                  NTC       PM10      PM2.5      PM1.0        CT1         CT2  \\\n",
      "Pred_Label                                                                      \n",
      "0           25.328815  45.924107  26.476603  20.867086   1.888156   74.907600   \n",
      "1           33.848240  64.429573  35.728271  29.934067   2.229311   77.759644   \n",
      "2           46.551517  79.486488  43.905872  36.574093   4.325107  103.002144   \n",
      "3           55.996967  83.563217  46.101151  38.225288  11.998965  188.793961   \n",
      "\n",
      "                  CT3        CT4  temp_max_value  ex_temperature  ex_humidity  \\\n",
      "Pred_Label                                                                      \n",
      "0           49.736904  19.701286       48.639317       25.492725    30.465984   \n",
      "1           50.959412  20.938372       68.617386       25.472527    30.538462   \n",
      "2           60.373280  29.944008       88.822441       25.479963    30.447344   \n",
      "3           90.458618  61.228874      107.409172       25.480459    30.452873   \n",
      "\n",
      "            ex_illuminance  \n",
      "Pred_Label                  \n",
      "0               155.620926  \n",
      "1               155.454544  \n",
      "2               155.336441  \n",
      "3               155.310349  \n",
      "Raw Logits: tensor([[  7.8358,   1.1560, -11.7019, -15.8426],\n",
      "        [  7.4806,   0.4598, -10.6230, -14.7163],\n",
      "        [  8.4694,   0.9436, -12.4614, -16.7161],\n",
      "        [  6.2500,   0.7581,  -9.0712, -12.8814],\n",
      "        [  7.2447,   0.9466, -10.6529, -14.6297]], device='cuda:0')\n",
      "Softmax Probabilities: tensor([[9.9875e-01, 1.2544e-03, 3.2684e-09, 5.2005e-11],\n",
      "        [9.9911e-01, 8.9226e-04, 1.3719e-08, 2.2887e-10],\n",
      "        [9.9946e-01, 5.3873e-04, 8.1214e-10, 1.1530e-11],\n",
      "        [9.9590e-01, 4.1031e-03, 2.2094e-07, 4.8928e-09],\n",
      "        [9.9816e-01, 1.8365e-03, 1.6843e-08, 3.1570e-10]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 로드\n",
    "def load_trained_model(model_path):\n",
    "    model = torch.load(model_path, map_location=device)  # 저장된 모델 전체 로드\n",
    "    model.eval()  # 평가 모드\n",
    "    print(\"모델 불러오기 완료\")\n",
    "    return model\n",
    "\n",
    "# 데이터 로드\n",
    "def load_test_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size):\n",
    "    test_dataset = MultimodalDataset(csv_path, bin_root_folder, \"test\", img_dim_h, img_dim_w)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "# 테스트 실행 함수\n",
    "def evaluate_model(model, test_loader, features, num_classes):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_aux_data = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "\n",
    "            # Softmax 적용\n",
    "            temperature = 2.0  # 온도 조정\n",
    "            probs = torch.softmax(outputs / temperature, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_aux_data.extend(aux_data.cpu().numpy())\n",
    "\n",
    "    # 결과 분석\n",
    "    df_results = pd.DataFrame(all_aux_data, columns=features)\n",
    "    df_results[\"True_Label\"] = all_labels\n",
    "    df_results[\"Pred_Label\"] = all_preds\n",
    "    df_results[\"Max_Prob\"] = np.max(all_probs, axis=1)\n",
    "\n",
    "    # 모델 성능 출력\n",
    "    print(\"\\n📊 Classification Report\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "    # 예측 클래스 분포 확인\n",
    "    unique, counts = np.unique(all_preds, return_counts=True)\n",
    "    print(\"Predicted Class Distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "    # 확률 분포 시각화\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for class_idx in range(num_classes):\n",
    "        class_probs = [prob[class_idx] for prob in all_probs]\n",
    "        plt.hist(class_probs, bins=30, alpha=0.5, label=f\"Class {class_idx}\")\n",
    "\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Probability Distribution of Each Class\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 변수별 평균값 출력\n",
    "    print(\"\\n Feature Statistics\")\n",
    "    feature_means = df_results.groupby(\"Pred_Label\")[features].mean()\n",
    "    print(\"\\n[각 클래스별 평균값]\")\n",
    "    print(feature_means)\n",
    "\n",
    "    # Softmax가 특정 클래스에 몰리는지 확인\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "            print(\"Raw Logits:\", outputs[:5])  # 처음 5개 샘플 출력\n",
    "            print(\"Softmax Probabilities:\", torch.softmax(outputs, dim=1)[:5])\n",
    "            break  # 한 번만 확인\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 경로 설정\n",
    "    csv_path = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV/agv_merged_output.csv\"\n",
    "    bin_root_folder = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV\"\n",
    "    model_path = \"AGV/agv12_best_model.pth\"\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    img_dim_h, img_dim_w = 120, 160\n",
    "    batch_size = 16\n",
    "    num_classes = 4\n",
    "    features = [\n",
    "        \"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\",\n",
    "        \"CT1\", \"CT2\", \"CT3\", \"CT4\",\n",
    "        \"temp_max_value\", \"ex_temperature\",\n",
    "        \"ex_humidity\", \"ex_illuminance\"\n",
    "    ]\n",
    "\n",
    "    # 모델 및 데이터 로드\n",
    "    model = load_trained_model(model_path)\n",
    "    test_loader = load_test_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size)\n",
    "\n",
    "    # 테스트 평가\n",
    "    evaluate_model(model, test_loader, features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ddc0bd-d7ef-44c4-8cce-ddc388e6e468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9b3a3-eef7-48fe-8b5c-2ac063bb6a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5c4aa-c9cd-4cef-8e01-09c40f4f6e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d4079-b107-4842-8b12-25d274a2d01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ddc78-8db8-4b85-8349-8238e2eb0366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b58892d4-6414-4139-8534-75cd79ee9a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "모델 불러오기 완료\n",
      "\n",
      "📊 Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9119    0.9288    0.9202      2584\n",
      "           1     0.8811    0.7353    0.8016      1088\n",
      "           2     0.8500    0.9124    0.8801      1050\n",
      "           3     0.8104    0.9455    0.8727       330\n",
      "\n",
      "    accuracy                         0.8848      5052\n",
      "   macro avg     0.8633    0.8805    0.8687      5052\n",
      "weighted avg     0.8857    0.8848    0.8832      5052\n",
      "\n",
      "Predicted Class Distribution: {0: 2632, 1: 908, 2: 1127, 3: 385}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 각 클래스별 Feature Range\n",
      "\n",
      "[각 클래스별 최소값]\n",
      "                  NTC  PM10  PM2.5  PM1.0   CT1        CT2        CT3  \\\n",
      "Pred_Label                                                              \n",
      "0           17.299999  38.0   20.0   16.0  1.50  74.400002  48.950001   \n",
      "1           19.980000  52.0   26.0   23.0  1.68  74.820000  49.849998   \n",
      "2           34.500000  67.0   38.0   31.0  1.60  74.779999  49.779999   \n",
      "3           50.480000  78.0   42.0   34.0  1.40  74.839996  49.720001   \n",
      "\n",
      "                  CT4  temp_max_value  ex_temperature  ex_humidity  \\\n",
      "Pred_Label                                                           \n",
      "0           18.950001       35.910000            25.0         27.0   \n",
      "1           19.900000       44.169998            25.0         27.0   \n",
      "2           19.830000       59.950001            25.0         27.0   \n",
      "3           19.670000       70.320000            25.0         27.0   \n",
      "\n",
      "            ex_illuminance  \n",
      "Pred_Label                  \n",
      "0                    151.0  \n",
      "1                    151.0  \n",
      "2                    151.0  \n",
      "3                    151.0  \n",
      "\n",
      "[각 클래스별 최대값]\n",
      "                  NTC  PM10  PM2.5  PM1.0         CT1         CT2         CT3  \\\n",
      "Pred_Label                                                                      \n",
      "0           32.599998  59.0   34.0   28.0    2.940000   77.470001   52.259998   \n",
      "1           46.160000  79.0   46.0   38.0   12.380000   87.760002   62.650002   \n",
      "2           57.560001  88.0   51.0   42.0   99.610001  161.839996  136.979996   \n",
      "3           59.939999  90.0   51.0   43.0  186.289993  269.500000  238.300003   \n",
      "\n",
      "                   CT4  temp_max_value  ex_temperature  ex_humidity  \\\n",
      "Pred_Label                                                            \n",
      "0            21.350000       83.900002            26.0         34.0   \n",
      "1            31.080000       91.879997            26.0         34.0   \n",
      "2           105.739998      127.610001            26.0         34.0   \n",
      "3           214.600006      138.960007            26.0         34.0   \n",
      "\n",
      "            ex_illuminance  \n",
      "Pred_Label                  \n",
      "0                    160.0  \n",
      "1                    160.0  \n",
      "2                    160.0  \n",
      "3                    160.0  \n",
      "\n",
      "[각 클래스별 범위 (Max - Min)]\n",
      "                  NTC  PM10  PM2.5  PM1.0         CT1         CT2         CT3  \\\n",
      "Pred_Label                                                                      \n",
      "0           15.299999  21.0   14.0   12.0    1.440000    3.070000    3.309998   \n",
      "1           26.180000  27.0   20.0   15.0   10.700000   12.940002   12.800003   \n",
      "2           23.060001  21.0   13.0   11.0   98.010002   87.059998   87.199997   \n",
      "3            9.459999  12.0    9.0    9.0  184.889999  194.660004  188.580002   \n",
      "\n",
      "                   CT4  temp_max_value  ex_temperature  ex_humidity  \\\n",
      "Pred_Label                                                            \n",
      "0             2.400000       47.990002             1.0          7.0   \n",
      "1            11.180000       47.709999             1.0          7.0   \n",
      "2            85.909996       67.660004             1.0          7.0   \n",
      "3           194.930008       68.640007             1.0          7.0   \n",
      "\n",
      "            ex_illuminance  \n",
      "Pred_Label                  \n",
      "0                      9.0  \n",
      "1                      9.0  \n",
      "2                      9.0  \n",
      "3                      9.0  \n",
      "Raw Logits: tensor([[ 3.4828,  1.2586, -8.0814, -6.6731],\n",
      "        [ 3.5603,  1.1340, -8.1483, -6.5646],\n",
      "        [ 3.6444,  1.0270, -8.3611, -6.5305],\n",
      "        [ 3.4146,  1.2011, -7.7811, -6.4742],\n",
      "        [ 3.4918,  1.1862, -8.0044, -6.5733]], device='cuda:0')\n",
      "Softmax Probabilities: tensor([[9.0236e-01, 9.7592e-02, 8.5725e-06, 3.5053e-05],\n",
      "        [9.1877e-01, 8.1184e-02, 7.5548e-06, 3.6814e-05],\n",
      "        [9.3193e-01, 6.8026e-02, 5.6942e-06, 3.5521e-05],\n",
      "        [9.0140e-01, 9.8537e-02, 1.2378e-05, 4.5735e-05],\n",
      "        [9.0930e-01, 9.0657e-02, 9.2459e-06, 3.8680e-05]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MultimodalDataset 클래스 (이전과 동일)\n",
    "class MultimodalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, bin_root_folder, split_folder, img_dim_h, img_dim_w):\n",
    "        self.data = []\n",
    "        self.img_dim_h = img_dim_h\n",
    "        self.img_dim_w = img_dim_w\n",
    "\n",
    "        # 모든 BIN 파일의 경로 수집\n",
    "        bin_files = {}\n",
    "        split_path = os.path.join(bin_root_folder, split_folder)\n",
    "        for root, _, files in os.walk(split_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".bin\"):\n",
    "                    bin_files[file] = os.path.join(root, file)\n",
    "\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(csv_path)\n",
    "        features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\",\n",
    "                    \"CT1\", \"CT2\", \"CT3\", \"CT4\",\n",
    "                    \"temp_max_value\", \"ex_temperature\", \"ex_humidity\", \"ex_illuminance\"]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            bin_filename = row['bin_filename']\n",
    "            if bin_filename in bin_files:\n",
    "                bin_path = bin_files[bin_filename]\n",
    "                try:\n",
    "                    img_data = np.load(bin_path).reshape((img_dim_h, img_dim_w))\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] BIN 파일 로드 실패: {bin_path}, {e}\")\n",
    "                    continue\n",
    "\n",
    "                aux_data = row[features].values.astype(np.float32)\n",
    "                label = int(row['state'])\n",
    "                self.data.append((img_data, aux_data, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data, aux_data, label = self.data[idx]\n",
    "        img_data = torch.tensor(img_data, dtype=torch.float32).unsqueeze(0)\n",
    "        aux_data = torch.tensor(aux_data, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img_data, aux_data, label\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 로드\n",
    "def load_trained_model(model_path):\n",
    "    model = torch.load(model_path, map_location=device)  # 저장된 모델 전체 로드\n",
    "    model.eval()  # 평가 모드\n",
    "    print(\"모델 불러오기 완료\")\n",
    "    return model\n",
    "\n",
    "# 데이터 로드\n",
    "def load_test_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size):\n",
    "    test_dataset = MultimodalDataset(csv_path, bin_root_folder, \"test\", img_dim_h, img_dim_w)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "# 테스트 실행 함수\n",
    "def evaluate_model(model, test_loader, features, num_classes):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_aux_data = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "\n",
    "            # Softmax 적용 (온도 조정)\n",
    "            temperature = 2.0  \n",
    "            probs = torch.softmax(outputs / temperature, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_aux_data.extend(aux_data.cpu().numpy())\n",
    "\n",
    "    # 결과 분석 DataFrame 생성\n",
    "    df_results = pd.DataFrame(all_aux_data, columns=features)\n",
    "    df_results[\"True_Label\"] = all_labels\n",
    "    df_results[\"Pred_Label\"] = all_preds\n",
    "    df_results[\"Max_Prob\"] = np.max(all_probs, axis=1)\n",
    "\n",
    "    # 모델 성능 출력\n",
    "    print(\"\\n📊 Classification Report\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "    # 예측 클래스 분포 확인\n",
    "    unique, counts = np.unique(all_preds, return_counts=True)\n",
    "    print(\"Predicted Class Distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "    # 확률 분포 시각화\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for class_idx in range(num_classes):\n",
    "        class_probs = [prob[class_idx] for prob in all_probs]\n",
    "        plt.hist(class_probs, bins=30, alpha=0.5, label=f\"Class {class_idx}\")\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Probability Distribution of Each Class\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 각 클래스별 feature의 최소, 최대 및 범위(range) 계산\n",
    "    print(\"\\n📊 각 클래스별 Feature Range\")\n",
    "    groupby_state = df_results.groupby(\"Pred_Label\")[features]\n",
    "    feature_min = groupby_state.min()\n",
    "    feature_max = groupby_state.max()\n",
    "    feature_range = feature_max - feature_min\n",
    "    print(\"\\n[각 클래스별 최소값]\")\n",
    "    print(feature_min)\n",
    "    print(\"\\n[각 클래스별 최대값]\")\n",
    "    print(feature_max)\n",
    "    print(\"\\n[각 클래스별 범위 (Max - Min)]\")\n",
    "    print(feature_range)\n",
    "\n",
    "    # 예시: 첫 5개 샘플의 Raw Logits와 Softmax 확률 확인\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "            print(\"Raw Logits:\", outputs[:5])\n",
    "            print(\"Softmax Probabilities:\", torch.softmax(outputs, dim=1)[:5])\n",
    "            break  # 한 번만 확인\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 경로 설정\n",
    "    csv_path = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV/agv_merged_output.csv\"\n",
    "    bin_root_folder = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV\"\n",
    "    model_path = \"AGV/agv12_best_model.pth\"\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    img_dim_h, img_dim_w = 120, 160\n",
    "    batch_size = 16\n",
    "    num_classes = 4\n",
    "    features = [\n",
    "        \"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\",\n",
    "        \"CT1\", \"CT2\", \"CT3\", \"CT4\",\n",
    "        \"temp_max_value\", \"ex_temperature\",\n",
    "        \"ex_humidity\", \"ex_illuminance\"\n",
    "    ]\n",
    "\n",
    "    # 모델 및 데이터 로드\n",
    "    model = load_trained_model(model_path)\n",
    "    test_loader = load_test_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size)\n",
    "\n",
    "    # 테스트 평가 및 각 state 별 feature 범위 확인\n",
    "    evaluate_model(model, test_loader, features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efb72523-dd24-4dbd-b038-45730f2bbebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "모델 불러오기 완료\n",
      "\n",
      "📊 Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9119    0.9288    0.9202      2584\n",
      "           1     0.8811    0.7353    0.8016      1088\n",
      "           2     0.8500    0.9124    0.8801      1050\n",
      "           3     0.8104    0.9455    0.8727       330\n",
      "\n",
      "    accuracy                         0.8848      5052\n",
      "   macro avg     0.8633    0.8805    0.8687      5052\n",
      "weighted avg     0.8857    0.8848    0.8832      5052\n",
      "\n",
      "Predicted Class Distribution: {0: 2632, 1: 908, 2: 1127, 3: 385}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[각 클래스별 평균 Feature 값]\n",
      "                  NTC       PM10      PM2.5      PM1.0        CT1         CT2  \\\n",
      "Pred_Label                                                                      \n",
      "0           25.415476  46.191109  26.609423  20.998859   1.892173   74.927582   \n",
      "1           34.446518  65.476875  36.223568  30.432819   2.270132   77.913864   \n",
      "2           46.821117  79.573204  43.976044  36.614906   5.033443  104.485428   \n",
      "3           56.268467  83.664932  46.158443  38.270130  10.855429  195.490448   \n",
      "\n",
      "                  CT3        CT4  temp_max_value  ex_temperature  ex_humidity  \\\n",
      "Pred_Label                                                                      \n",
      "0           49.747871  19.719061       49.217484       25.494680    30.464285   \n",
      "1           51.029758  21.084173       68.762711       25.464758    30.569384   \n",
      "2           61.031021  30.545572       89.550957       25.480036    30.417036   \n",
      "3           92.384338  63.257923      107.803535       25.480520    30.498701   \n",
      "\n",
      "            ex_illuminance  \n",
      "Pred_Label                  \n",
      "0               155.609421  \n",
      "1               155.480179  \n",
      "2               155.352264  \n",
      "3               155.241562  \n",
      "\n",
      "[각 Feature별 임계값 (인접 클래스 평균 중간값)]\n",
      "NTC: {'State 0 vs State 1': 29.93099594116211, 'State 1 vs State 2': 40.633819580078125, 'State 2 vs State 3': 51.54479217529297}\n",
      "PM10: {'State 0 vs State 1': 55.83399200439453, 'State 1 vs State 2': 72.52503967285156, 'State 2 vs State 3': 81.61906433105469}\n",
      "PM2.5: {'State 0 vs State 1': 31.41649627685547, 'State 1 vs State 2': 40.09980773925781, 'State 2 vs State 3': 45.06724548339844}\n",
      "PM1.0: {'State 0 vs State 1': 25.715839385986328, 'State 1 vs State 2': 33.52386474609375, 'State 2 vs State 3': 37.44252014160156}\n",
      "CT1: {'State 0 vs State 1': 2.0811526775360107, 'State 1 vs State 2': 3.651787519454956, 'State 2 vs State 3': 7.944436073303223}\n",
      "CT2: {'State 0 vs State 1': 76.42072296142578, 'State 1 vs State 2': 91.19964599609375, 'State 2 vs State 3': 149.98794555664062}\n",
      "CT3: {'State 0 vs State 1': 50.388816833496094, 'State 1 vs State 2': 56.03038787841797, 'State 2 vs State 3': 76.70767974853516}\n",
      "CT4: {'State 0 vs State 1': 20.4016170501709, 'State 1 vs State 2': 25.81487274169922, 'State 2 vs State 3': 46.90174865722656}\n",
      "temp_max_value: {'State 0 vs State 1': 58.99009704589844, 'State 1 vs State 2': 79.15682983398438, 'State 2 vs State 3': 98.67724609375}\n",
      "ex_temperature: {'State 0 vs State 1': 25.479719161987305, 'State 1 vs State 2': 25.472396850585938, 'State 2 vs State 3': 25.48027801513672}\n",
      "ex_humidity: {'State 0 vs State 1': 30.516834259033203, 'State 1 vs State 2': 30.493209838867188, 'State 2 vs State 3': 30.457868576049805}\n",
      "ex_illuminance: {'State 0 vs State 1': 155.5447998046875, 'State 1 vs State 2': 155.41622924804688, 'State 2 vs State 3': 155.29690551757812}\n",
      "Raw Logits (first 5 samples): tensor([[ 3.4828,  1.2586, -8.0814, -6.6731],\n",
      "        [ 3.5603,  1.1340, -8.1483, -6.5646],\n",
      "        [ 3.6444,  1.0270, -8.3611, -6.5305],\n",
      "        [ 3.4146,  1.2011, -7.7811, -6.4742],\n",
      "        [ 3.4918,  1.1862, -8.0044, -6.5733]], device='cuda:0')\n",
      "Softmax Probabilities (first 5 samples): tensor([[9.0236e-01, 9.7592e-02, 8.5725e-06, 3.5053e-05],\n",
      "        [9.1877e-01, 8.1184e-02, 7.5548e-06, 3.6814e-05],\n",
      "        [9.3193e-01, 6.8026e-02, 5.6942e-06, 3.5521e-05],\n",
      "        [9.0140e-01, 9.8537e-02, 1.2378e-05, 4.5735e-05],\n",
      "        [9.0930e-01, 9.0657e-02, 9.2459e-06, 3.8680e-05]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MultimodalDataset 클래스 (이전과 동일)\n",
    "class MultimodalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, bin_root_folder, split_folder, img_dim_h, img_dim_w):\n",
    "        self.data = []\n",
    "        self.img_dim_h = img_dim_h\n",
    "        self.img_dim_w = img_dim_w\n",
    "\n",
    "        # 모든 BIN 파일의 경로 수집\n",
    "        bin_files = {}\n",
    "        split_path = os.path.join(bin_root_folder, split_folder)\n",
    "        for root, _, files in os.walk(split_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".bin\"):\n",
    "                    bin_files[file] = os.path.join(root, file)\n",
    "\n",
    "        # CSV 파일 읽기\n",
    "        df = pd.read_csv(csv_path)\n",
    "        features = [\"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\",\n",
    "                    \"CT1\", \"CT2\", \"CT3\", \"CT4\",\n",
    "                    \"temp_max_value\", \"ex_temperature\", \"ex_humidity\", \"ex_illuminance\"]\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            bin_filename = row['bin_filename']\n",
    "            if bin_filename in bin_files:\n",
    "                bin_path = bin_files[bin_filename]\n",
    "                try:\n",
    "                    img_data = np.load(bin_path).reshape((img_dim_h, img_dim_w))\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] BIN 파일 로드 실패: {bin_path}, {e}\")\n",
    "                    continue\n",
    "\n",
    "                aux_data = row[features].values.astype(np.float32)\n",
    "                label = int(row['state'])\n",
    "                self.data.append((img_data, aux_data, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_data, aux_data, label = self.data[idx]\n",
    "        img_data = torch.tensor(img_data, dtype=torch.float32).unsqueeze(0)\n",
    "        aux_data = torch.tensor(aux_data, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img_data, aux_data, label\n",
    "\n",
    "# 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 모델 로드 함수\n",
    "def load_trained_model(model_path):\n",
    "    model = torch.load(model_path, map_location=device)  # 저장된 모델 전체 로드\n",
    "    model.eval()  # 평가 모드\n",
    "    print(\"모델 불러오기 완료\")\n",
    "    return model\n",
    "\n",
    "# 데이터 로드 함수\n",
    "def load_test_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size):\n",
    "    test_dataset = MultimodalDataset(csv_path, bin_root_folder, \"test\", img_dim_h, img_dim_w)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return test_loader\n",
    "\n",
    "# 평가 함수 (각 클래스별 feature 임계값 추가 계산)\n",
    "def evaluate_model(model, test_loader, features, num_classes):\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_aux_data = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "\n",
    "            # 온도 조정을 통한 softmax 적용\n",
    "            temperature = 2.0  \n",
    "            probs = torch.softmax(outputs / temperature, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_aux_data.extend(aux_data.cpu().numpy())\n",
    "\n",
    "    # 결과 DataFrame 생성: 각 보조 feature와 실제/예측 레이블 저장\n",
    "    df_results = pd.DataFrame(all_aux_data, columns=features)\n",
    "    df_results[\"True_Label\"] = all_labels\n",
    "    df_results[\"Pred_Label\"] = all_preds\n",
    "    df_results[\"Max_Prob\"] = np.max(all_probs, axis=1)\n",
    "\n",
    "    # 모델 성능 출력\n",
    "    print(\"\\n📊 Classification Report\")\n",
    "    print(classification_report(all_labels, all_preds, digits=4))\n",
    "\n",
    "    unique, counts = np.unique(all_preds, return_counts=True)\n",
    "    print(\"Predicted Class Distribution:\", dict(zip(unique, counts)))\n",
    "\n",
    "    # 확률 분포 시각화\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for class_idx in range(num_classes):\n",
    "        class_probs = [prob[class_idx] for prob in all_probs]\n",
    "        plt.hist(class_probs, bins=30, alpha=0.5, label=f\"Class {class_idx}\")\n",
    "    plt.xlabel(\"Prediction Probability\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Probability Distribution of Each Class\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 각 클래스별 feature 평균값 계산 (예측된 클래스 기준)\n",
    "    print(\"\\n[각 클래스별 평균 Feature 값]\")\n",
    "    groupby_state = df_results.groupby(\"Pred_Label\")[features]\n",
    "    feature_means = groupby_state.mean()\n",
    "    print(feature_means)\n",
    "\n",
    "    # 임계값 계산: 각 feature에 대해 인접 클래스의 평균값 중간값 산출\n",
    "    print(\"\\n[각 Feature별 임계값 (인접 클래스 평균 중간값)]\")\n",
    "    thresholds = {}  # {feature: {state_i vs state_j: threshold, ...}, ...}\n",
    "    for feature in features:\n",
    "        # 클래스별 평균을 클래스 레이블 순으로 정렬 (0, 1, 2, 3 등)\n",
    "        means = feature_means[feature].sort_index()\n",
    "        feature_thresholds = {}\n",
    "        for i in range(len(means) - 1):\n",
    "            # 인접한 두 클래스의 평균값 중간값을 임계값으로 산출\n",
    "            thresh = (means.iloc[i] + means.iloc[i + 1]) / 2.0\n",
    "            feature_thresholds[f\"State {means.index[i]} vs State {means.index[i+1]}\"] = thresh\n",
    "        thresholds[feature] = feature_thresholds\n",
    "        print(f\"{feature}: {feature_thresholds}\")\n",
    "\n",
    "    # 예시로 첫 5개 샘플의 Raw Logits와 Softmax 확률 확인\n",
    "    with torch.no_grad():\n",
    "        for images, aux_data, labels in test_loader:\n",
    "            images, aux_data, labels = images.to(device), aux_data.to(device), labels.to(device)\n",
    "            outputs = model(images, aux_data)\n",
    "            print(\"Raw Logits (first 5 samples):\", outputs[:5])\n",
    "            print(\"Softmax Probabilities (first 5 samples):\", torch.softmax(outputs, dim=1)[:5])\n",
    "            break\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV/agv_merged_output.csv\"\n",
    "    bin_root_folder = \"C:/Users/82103/Desktop/multimodal/train(01~14)val(15~16)test(17~18)/AGV\"\n",
    "    model_path = \"AGV/agv12_best_model.pth\"\n",
    "\n",
    "    # 하이퍼파라미터 설정\n",
    "    img_dim_h, img_dim_w = 120, 160\n",
    "    batch_size = 16\n",
    "    num_classes = 4\n",
    "    features = [\n",
    "        \"NTC\", \"PM10\", \"PM2.5\", \"PM1.0\",\n",
    "        \"CT1\", \"CT2\", \"CT3\", \"CT4\",\n",
    "        \"temp_max_value\", \"ex_temperature\",\n",
    "        \"ex_humidity\", \"ex_illuminance\"\n",
    "    ]\n",
    "\n",
    "    model = load_trained_model(model_path)\n",
    "    test_loader = load_test_data(csv_path, bin_root_folder, img_dim_h, img_dim_w, batch_size)\n",
    "\n",
    "    evaluate_model(model, test_loader, features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d1f76b8-695a-4731-ae86-c15f9fcb79ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu111\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda11.1",
   "language": "python",
   "name": "tf37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
