from fastapi import APIRouter, HTTPException
from langchain.chains import RetrievalQA
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain_core.prompts import PromptTemplate
import os

router = APIRouter()

# ì „ì—­ ë³€ìˆ˜
qa_chain = None
openai_api_key = None

# OpenAI API í‚¤ ë¡œë“œ
def load_file(filepath):
    with open(filepath, 'r') as file:
        return file.readline().strip()

# ë²¡í„°ìŠ¤í† ì–´ ë° QA ì²´ì¸ ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_chatbot():
    global qa_chain, openai_api_key
    
    try:
        # API í‚¤ ë¡œë“œ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        openai_api_key = load_file('chatbot/api_key.txt')
        os.environ['OPENAI_API_KEY'] = openai_api_key

        # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
        embeddings_model = OpenAIEmbeddings(openai_api_key=openai_api_key)
        vectorstore = FAISS.load_local("chatbot/faiss_index", embeddings_model, allow_dangerous_deserialization=True)

        # QA ì²´ì¸ ì„¤ì •
        prompt = PromptTemplate.from_template(
            """ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
            ì£¼ì–´ì§„ ë¬¸ë§¥(context)ì—ì„œ ì§ˆë¬¸(question)ì— ë‹µí•˜ì„¸ìš”.
            ë¬¸ë§¥ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ `ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤`ë¼ê³  ë‹µí•˜ì„¸ìš”.

            # ì§ˆë¬¸:
            {question}

            # ë¬¸ë§¥:
            {context}

            # ë‹µë³€: (ìì„¸í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”)
            """
        )
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=vectorstore.as_retriever(),
            chain_type_kwargs={"prompt": prompt},
            return_source_documents=True
        )

        print("ğŸ“¢ ì±—ë´‡ ì´ˆê¸°í™” ì™„ë£Œ!")
    except Exception as e:
        print(f"ğŸš¨ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# FastAPI ì‹œì‘ ì‹œ ì±—ë´‡ ì´ˆê¸°í™”
initialize_chatbot()

@router.get("/api")
async def chat_endpoint(question: str):
    """ì±—ë´‡ API ì—”ë“œí¬ì¸íŠ¸"""
    global qa_chain
    if qa_chain is None:
        raise HTTPException(status_code=500, detail="ì±—ë´‡ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    try:
        response = qa_chain.invoke({"query": question})
        return {"answer": response["result"]}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
