# ê¸°ë³¸ Python ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import sys
import json
import requests
import xml.etree.ElementTree as ET
 
# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd
from dotenv import load_dotenv
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from weasyprint import HTML  # âœ… WeasyPrint ì¶”ê°€
 
# OpenAI ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
import openai
from openai import OpenAI
 
# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
 
import joblib
from datetime import datetime
from langchain.chains import LLMChain
from fastapi.responses import FileResponse
from pydantic import BaseModel  # âœ… Pydantic ê°€ì ¸ì˜¤ê¸°
 
router = APIRouter()

# ì „ì—­ ë³€ìˆ˜
qa_chain = None
openai_api_key = None
 
# ğŸ”¹ PDF ì €ì¥ ê²½ë¡œ ì„¤ì •
REPORTS_DIR = "reports"
os.makedirs(REPORTS_DIR, exist_ok=True)  # ğŸ“‚ í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
 
# âœ… ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def load_file(filepath):
    with open(filepath, "r") as file:
        return file.readline().strip()
 
 
def load_csv(file_path):
    try:
        df = pd.read_csv(file_path, encoding="euc-kr")
        print(f"Loaded {len(df)} rows and {len(df.columns)} columns.")
        return df
    except UnicodeDecodeError:
        raise ValueError("Error: Unable to decode the file. Please check the file encoding.")
 
 
def extract_text_data(df):
    if {"êµ¬ë¶„", "ë‚´ìš©"}.issubset(df.columns):
        return [f"êµ¬ë¶„: {row['êµ¬ë¶„']}\në‚´ìš©: {row['ë‚´ìš©']}" for _, row in df.iterrows()]
    else:
        raise ValueError("The required columns ('êµ¬ë¶„', 'ë‚´ìš©') are not found in the CSV file.")
 
 
def split_texts(text_data, chunk_size=1000, chunk_overlap=100):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    split_docs = []
    for text in text_data:
        split_docs.extend(text_splitter.split_text(text))
    print(f"Split into {len(split_docs)} chunks.")
    return split_docs
 
 
def create_vectorstore(split_docs, embeddings_model):
    try:
        vectorstore = FAISS.from_texts(split_docs, embeddings_model)
        print("Embeddings created and vectorstore generated.")
        return vectorstore
    except Exception as e:
        raise RuntimeError(f"Error during embeddings creation: {e}")
 
 
def save_vectorstore(vectorstore, path):
    vectorstore.save_local(path)
    print(f"Vectorstore saved locally as '{path}'.")
 
 
def load_vectorstore(path, embeddings_model):
    return FAISS.load_local(path, embeddings_model, allow_dangerous_deserialization=True)
 
 
def setup_qa_chain(vectorstore):
    prompt = PromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ì§ˆë¬¸-ë‹µë³€(Question-Answering)ì„ ìˆ˜í–‰í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥(context) ì—ì„œ ì£¼ì–´ì§„ ì§ˆë¬¸(question) ì— ë‹µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
        ê²€ìƒ‰ëœ ë‹¤ìŒ ë¬¸ë§¥(context) ì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸(question) ì— ë‹µí•˜ì„¸ìš”. ë§Œì•½, ì£¼ì–´ì§„ ë¬¸ë§¥(context) ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ `ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤` ë¼ê³  ë‹µí•˜ì„¸ìš”.
        í•œê¸€ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”. ë‹¨, ê¸°ìˆ ì ì¸ ìš©ì–´ë‚˜ ì´ë¦„ì€ ë²ˆì—­í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.
 
        #Question:
        {question}
 
        #Context:
        {context}
 
        #Answer: (ìì„¸í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”)"""
    )
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)
 
    return RetrievalQA.from_chain_type(
        llm=llm,
        retriever=vectorstore.as_retriever(),
        chain_type_kwargs={"prompt": prompt},
        return_source_documents=True
    )
 
 
# âœ… ì•± ì‹œì‘ ì‹œ ì´ˆê¸°í™”
@router.on_event("startup")
async def startup_event():
    global qa_chain, openai_api_key
    
    try:
        # API í‚¤ ë¡œë“œ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        openai_api_key = load_file("./chatbot/api_key.txt")
        os.environ["OPENAI_API_KEY"] = openai_api_key
 
        # CSV ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
        file_path = "./report/example.csv"
        df = load_csv(file_path)
        text_data = extract_text_data(df)
 
        # í…ìŠ¤íŠ¸ ë¶„í• 
        split_docs = split_texts(text_data)
 
        # ì„ë² ë”© ëª¨ë¸ ë° ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •
        embeddings_model = OpenAIEmbeddings(openai_api_key=openai_api_key)
        vectorstore = create_vectorstore(split_docs, embeddings_model)
        save_vectorstore(vectorstore, "faiss_index")
 
        # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ë° QA ì²´ì¸ ì„¤ì •
        vectorstore = load_vectorstore("faiss_index", embeddings_model)
        qa_chain = setup_qa_chain(vectorstore)
 
        print("routerlication successfully initialized!")
    except Exception as e:
        print(f"Error during initialization: {e}")
        sys.exit(1)
 
# âœ… ì±—ë´‡ API ì—”ë“œí¬ì¸íŠ¸
@router.get("/")
def read_root():
    return {"message": "Welcome to QA Chatbot API!"}
 
@router.get("/chat-bot")
async def chat_endpoint(question: str):
    global qa_chain
    try:
        if qa_chain is None:
            raise HTTPException(status_code=500, detail="QA chain not initialized")
        
        response = qa_chain.invoke({"query": question})
        return response["result"]
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
 
# âœ… PDF ë³´ê³ ì„œ ìƒì„± (WeasyPrint ì‚¬ìš©)
def generate_pdf_report(html_content, filename):
    pdf_path = os.path.join(REPORTS_DIR, filename)
    HTML(string=html_content).write_pdf(pdf_path)
    return pdf_path
# âœ… EquipmentReportRequest ëª¨ë¸ ì •ì˜ ì¶”ê°€
class EquipmentReportRequest(BaseModel):
    ì¥ë¹„_ID: str
    ì‹œì‘_ë‚ ì§œ: str  # MM-DD í˜•ì‹
    ì¢…ë£Œ_ë‚ ì§œ: str  # MM-DD í˜•ì‹
    
@router.post("/generate-equipment-report")
async def generate_equipment_report(request: EquipmentReportRequest):
    try:
        # âœ… HTML ë³´ê³ ì„œ ìƒì„±
        html_content = f"""
        <html>
        <head><meta charset="UTF-8"></head>
        <body>
            <h1>{request.ì¥ë¹„_ID} ì •ë¹„ ë³´ê³ ì„œ</h1>
            <p>ìš´ì˜ ê¸°ê°„: {request.ì‹œì‘_ë‚ ì§œ} ~ {request.ì¢…ë£Œ_ë‚ ì§œ}</p>
            <h2>AI ë¶„ì„ ë³´ê³ </h2>
            <p>ì¥ë¹„ì˜ ìƒíƒœì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ê°€ ì—¬ê¸°ì— í¬í•¨ë©ë‹ˆë‹¤.</p>
        </body>
        </html>
        """
 
        # âœ… PDF íŒŒì¼ ìƒì„±
        pdf_filename = f"{request.ì¥ë¹„_ID}_report.pdf"
        pdf_path = generate_pdf_report(html_content, pdf_filename)
 
        # âœ… ì‘ë‹µ ë°˜í™˜
        return {
            "message": "ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ",
            "pdf_filename": pdf_filename,
            "download_url": f"/rep/download-report/{pdf_filename}",
        }
 
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
 
@router.get("/download-report/{filename}")
async def download_report(filename: str):
    file_path = os.path.join(REPORTS_DIR, filename)
    if not os.path.exists(file_path):
        return {"error": "íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    return FileResponse(file_path, filename=filename, media_type="routerlication/pdf")
 