{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agv12_table에 데이터 삽입 완료\n",
      "agv13_table에 데이터 삽입 완료\n",
      "agv14_table에 데이터 삽입 완료\n",
      "agv15_table에 데이터 삽입 완료\n",
      "agv16_table에 데이터 삽입 완료\n",
      "oht12_table에 데이터 삽입 완료\n",
      "oht13_table에 데이터 삽입 완료\n",
      "oht14_table에 데이터 삽입 완료\n",
      "oht15_table에 데이터 삽입 완료\n",
      "oht16_table에 데이터 삽입 완료\n",
      "\n",
      "[2025-01-23 17:53:32] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 17:53:32] AGV13 분석 시작\n",
      "\n",
      "[2025-01-23 17:53:32] AGV14 분석 시작\n",
      "\n",
      "[2025-01-23 17:53:32] AGV15 분석 시작\n",
      "\n",
      "[2025-01-23 17:53:32] AGV16 분석 시작\n",
      "\n",
      "\n",
      "====== 기기 상태 모니터링 ======\n",
      "[2025-01-23 17:53:32]\n",
      "\n",
      "\n",
      "====== 기기 상태 모니터링 ======\n",
      "[2025-01-23 17:54:02]\n",
      "\n",
      "AGV12:\n",
      "상태: 정상\n",
      "정상: 100.0%\n",
      "주의: 0.0%\n",
      "경고: 0.0%\n",
      "위험: 0.0%\n",
      "\n",
      "AGV13:\n",
      "상태: 정상\n",
      "정상: 100.0%\n",
      "주의: 0.0%\n",
      "경고: 0.0%\n",
      "위험: 0.0%\n",
      "\n",
      "AGV14:\n",
      "상태: 정상\n",
      "정상: 100.0%\n",
      "주의: 0.0%\n",
      "경고: 0.0%\n",
      "위험: 0.0%\n",
      "\n",
      "AGV15:\n",
      "상태: 정상\n",
      "정상: 100.0%\n",
      "주의: 0.0%\n",
      "경고: 0.0%\n",
      "위험: 0.0%\n",
      "\n",
      "AGV16:\n",
      "상태: 정상\n",
      "정상: 100.0%\n",
      "주의: 0.0%\n",
      "경고: 0.0%\n",
      "위험: 0.0%\n",
      "\n",
      "모니터링을 종료합니다...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-01-23 18:12:29] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 18:16:44] AGV15 분석 시작\n",
      "[2025-01-23 18:16:44] AGV16 분석 시작\n",
      "\n",
      "\n",
      "[2025-01-23 18:16:44] AGV13 분석 시작\n",
      "\n",
      "[2025-01-23 18:16:52] AGV14 분석 시작\n",
      "\n",
      "[2025-01-23 18:26:39] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 18:36:17] AGV13 분석 시작\n",
      "\n",
      "[2025-01-23 18:36:17] AGV15 분석 시작\n",
      "\n",
      "[2025-01-23 18:36:18] AGV16 분석 시작\n",
      "\n",
      "[2025-01-23 18:36:25] AGV14 분석 시작\n",
      "\n",
      "[2025-01-23 18:40:44] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 18:55:47] AGV13 분석 시작\n",
      "\n",
      "[2025-01-23 18:55:50] AGV15 분석 시작\n",
      "\n",
      "[2025-01-23 18:55:58] AGV14 분석 시작\n",
      "\n",
      "[2025-01-23 18:55:58] AGV16 분석 시작\n",
      "\n",
      "[2025-01-23 18:55:58] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 19:11:32] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 19:14:59] AGV13 분석 시작\n",
      "\n",
      "[2025-01-23 19:15:11] AGV15 분석 시작\n",
      "\n",
      "[2025-01-23 19:15:21] AGV14 분석 시작\n",
      "\n",
      "[2025-01-23 19:15:30] AGV16 분석 시작\n",
      "\n",
      "[2025-01-23 19:25:58] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 19:34:18] AGV13 분석 시작\n",
      "\n",
      "[2025-01-23 19:34:44] AGV15 분석 시작\n",
      "\n",
      "[2025-01-23 19:34:52] AGV16 분석 시작\n",
      "\n",
      "[2025-01-23 19:34:52] AGV14 분석 시작\n",
      "\n",
      "[2025-01-23 19:40:20] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 19:53:08] AGV13 분석 시작\n",
      "\n",
      "[2025-01-23 19:54:01] AGV16 분석 시작\n",
      "\n",
      "[2025-01-23 19:54:02] AGV15 분석 시작\n",
      "\n",
      "[2025-01-23 19:54:11] AGV14 분석 시작\n",
      "\n",
      "[2025-01-23 19:54:49] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 20:09:58] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 20:11:42] AGV13 분석 시작\n",
      "\n",
      "[2025-01-23 20:13:01] AGV15 분석 시작\n",
      "\n",
      "[2025-01-23 20:13:03] AGV16 분석 시작\n",
      "\n",
      "[2025-01-23 20:13:11] AGV14 분석 시작\n",
      "\n",
      "[2025-01-23 20:24:18] AGV12 분석 시작\n",
      "\n",
      "[2025-01-23 20:31:13] AGV13 분석 시작\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os, sys, time, threading\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from warnings import filterwarnings\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from MultiModal.dataset import MultimodalTestDataset\n",
    "from MultiModal.model import (\n",
    "   CrossAttention, \n",
    "   SoftLabelEncoder,\n",
    "   ViTFeatureExtractor, \n",
    "   ConditionClassifier\n",
    ")\n",
    "\n",
    "filterwarnings(action='ignore')\n",
    "\n",
    "base_path = '/Users/hwangeunbi/Desktop/빅프로젝트/MultiModal_AI_1/data'\n",
    "# DB 파일 경로 설정\n",
    "db_path = '/Users/hwangeunbi/Desktop/빅프로젝트/MultiModal_AI_1/sensor_data.db'\n",
    "\n",
    "def get_db_connection():\n",
    "    return sqlite3.connect(db_path)\n",
    "\n",
    "def create_monitoring_table():\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS device_status (\n",
    "        device_id TEXT,\n",
    "        status TEXT,\n",
    "        timestamp DATETIME,\n",
    "        normal_ratio REAL,\n",
    "        caution_ratio REAL,\n",
    "        warning_ratio REAL,\n",
    "        risk_ratio REAL,\n",
    "        PRIMARY KEY (device_id, timestamp)\n",
    "    )\n",
    "    ''')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "device = 'cpu'\n",
    "model_config = {\n",
    "   'img_dim_h': 120, 'img_dim_w': 160,\n",
    "   'patch_size': 16, 'embed_dim': 128,\n",
    "   'num_heads': 4, 'depth': 6,\n",
    "   'aux_input_dim': 11, 'num_classes': 4\n",
    "}\n",
    "\n",
    "def create_monitoring_table():\n",
    "   conn = sqlite3.connect('sensor_data.db')\n",
    "   cursor = conn.cursor()\n",
    "   cursor.execute('''\n",
    "   CREATE TABLE IF NOT EXISTS device_status (\n",
    "       device_id TEXT,\n",
    "       status TEXT,\n",
    "       timestamp DATETIME,\n",
    "       normal_ratio REAL,\n",
    "       caution_ratio REAL,\n",
    "       warning_ratio REAL,\n",
    "       risk_ratio REAL,\n",
    "       PRIMARY KEY (device_id, timestamp)\n",
    "   )\n",
    "   ''')\n",
    "   conn.commit()\n",
    "   conn.close()\n",
    "\n",
    "def create_sensor_table():\n",
    "   conn = sqlite3.connect('sensor_data.db')\n",
    "   cursor = conn.cursor()\n",
    "   cursor.execute('''\n",
    "   CREATE TABLE IF NOT EXISTS sensor_measurements (\n",
    "       device_id TEXT,\n",
    "       timestamp DATETIME,\n",
    "       sensor_name TEXT,\n",
    "       sensor_value REAL,\n",
    "       PRIMARY KEY (device_id, timestamp, sensor_name)\n",
    "   )\n",
    "   ''')\n",
    "   conn.commit()\n",
    "   conn.close()\n",
    "\n",
    "def update_device_status(device_id, status, normal_ratio, caution_ratio, warning_ratio, risk_ratio):\n",
    "   conn = sqlite3.connect('sensor_data.db')\n",
    "   cursor = conn.cursor()\n",
    "   cursor.execute('''\n",
    "   INSERT OR REPLACE INTO device_status\n",
    "   VALUES (?, ?, datetime('now', 'localtime'), ?, ?, ?, ?)\n",
    "   ''', (device_id, status, normal_ratio, caution_ratio, warning_ratio, risk_ratio))\n",
    "   conn.commit()\n",
    "   conn.close()\n",
    "\n",
    "def insert_sensor_measurements(device_id, window_data, is_first_window=False):\n",
    "   conn = sqlite3.connect('sensor_data.db')\n",
    "   cursor = conn.cursor()\n",
    "   \n",
    "   data_to_insert = window_data if is_first_window else window_data.tail(30)\n",
    "   sensor_columns = [col for col in window_data.columns \n",
    "                    if col not in ['device_id', 'timestamp', 'filenames']]\n",
    "   \n",
    "   timestamp = datetime.now()\n",
    "   for idx, row in data_to_insert.iterrows():\n",
    "       current_timestamp = timestamp + timedelta(seconds=idx)\n",
    "       for sensor in sensor_columns:\n",
    "           cursor.execute('''\n",
    "           INSERT OR REPLACE INTO sensor_measurements \n",
    "           VALUES (?, ?, ?, ?)\n",
    "           ''', (device_id, current_timestamp, sensor, float(row[sensor])))\n",
    "           \n",
    "   conn.commit()\n",
    "   conn.close()\n",
    "\n",
    "def get_latest_status():\n",
    "   conn = sqlite3.connect('sensor_data.db')\n",
    "   cursor = conn.cursor()\n",
    "   cursor.execute('''\n",
    "   SELECT device_id, status, timestamp, normal_ratio, caution_ratio, warning_ratio, risk_ratio\n",
    "   FROM device_status\n",
    "   GROUP BY device_id\n",
    "   HAVING timestamp = MAX(timestamp)\n",
    "   ''')\n",
    "   results = cursor.fetchall()\n",
    "   conn.close()\n",
    "   return results\n",
    "\n",
    "def load_model(device_type):\n",
    "   model = ConditionClassifier(**model_config)\n",
    "   path = f'Parameters/{device_type}_Best_State_Model.pth'\n",
    "   model.load_state_dict(torch.load(path, map_location='cpu'))\n",
    "   return model.eval()\n",
    "\n",
    "def load_data():\n",
    "   agv_data = {}\n",
    "   for i in range(12, 17):\n",
    "       with open(f'{base_path}/agv{i}_test_df', 'rb') as file:\n",
    "           agv_data[i] = joblib.load(file)\n",
    "           \n",
    "   oht_data = {}\n",
    "   for i in range(12, 17):\n",
    "       with open(f'{base_path}/oht{i}_test_df', 'rb') as file:\n",
    "           oht_data[i] = joblib.load(file)\n",
    "\n",
    "   for dataset in [agv_data, oht_data]:\n",
    "       for key, df in dataset.items():\n",
    "           df.columns = [col.replace('.', '_') for col in df.columns]\n",
    "           if 'filenames' in df.columns:\n",
    "               df['filenames'] = df['filenames'].str.replace('\\\\', '/', regex=False)\n",
    "           df.drop(columns=['device_id', 'collection_date', 'collection_time', 'cumulative_operating_day'], \n",
    "                   inplace=True)\n",
    "   \n",
    "   return agv_data, oht_data\n",
    "\n",
    "def create_and_populate_tables(data_dict, prefix):\n",
    "   conn = sqlite3.connect('sensor_data.db')\n",
    "   for i, df in data_dict.items():\n",
    "       table_name = f'{prefix}{i}_table'\n",
    "       df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "       print(f'{table_name}에 데이터 삽입 완료')\n",
    "   conn.close()\n",
    "\n",
    "def check_device_status(device_id):\n",
    "   device_type = 'oht' if 'oht' in device_id.lower() else 'agv'\n",
    "   number = ''.join(filter(str.isdigit, device_id))\n",
    "   table = f\"{device_type}{number}_table\"\n",
    "\n",
    "   conn = sqlite3.connect('sensor_data.db')\n",
    "   df = pd.read_sql(f'SELECT * FROM {table}', conn)\n",
    "   conn.close()\n",
    "\n",
    "   window_size = 300\n",
    "   step_size = 30\n",
    "\n",
    "   for start in range(0, len(df) - window_size + 1, step_size):\n",
    "       window = df.iloc[start:start + window_size]\n",
    "       is_first_window = (start == 0)\n",
    "       \n",
    "       dataset = MultimodalTestDataset(window)\n",
    "       dataloader = DataLoader(dataset, batch_size=window_size)\n",
    "       images, sensors = next(iter(dataloader))\n",
    "\n",
    "       model = load_model(device_type.upper())\n",
    "       with torch.no_grad():\n",
    "           prediction = torch.argmax(model(images, sensors), dim=1)\n",
    "\n",
    "       risk = (prediction == 3).sum().item()\n",
    "       warning = (prediction == 2).sum().item()\n",
    "       caution = (prediction == 1).sum().item()\n",
    "       normal = (prediction == 0).sum().item()\n",
    "\n",
    "       total = window_size\n",
    "       risk_ratio = (risk / total) * 100\n",
    "       warning_ratio = (warning / total) * 100\n",
    "       caution_ratio = (caution / total) * 100\n",
    "       normal_ratio = (normal / total) * 100\n",
    "\n",
    "       current_status = \"\"\n",
    "       if device_type == 'agv':\n",
    "           if risk >= 20: current_status = \"위험\"\n",
    "           elif warning >= 60: current_status = \"경고\"\n",
    "           elif caution >= 80: current_status = \"주의\"\n",
    "           else: current_status = \"정상\"\n",
    "       else:\n",
    "           if risk >= 15: current_status = \"위험\"\n",
    "           elif warning >= 50: current_status = \"경고\"\n",
    "           elif caution >= 70: current_status = \"주의\"\n",
    "           else: current_status = \"정상\"\n",
    "\n",
    "       update_device_status(device_id, current_status, normal_ratio, caution_ratio, warning_ratio, risk_ratio)\n",
    "       insert_sensor_measurements(device_id, window, is_first_window)\n",
    "\n",
    "def monitor_device(device_id):\n",
    "   try:\n",
    "       while True:\n",
    "           current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "           print(f\"\\n[{current_time}] {device_id} 분석 시작\")\n",
    "           check_device_status(device_id)\n",
    "           time.sleep(30)\n",
    "   except KeyboardInterrupt:\n",
    "       return\n",
    "\n",
    "def monitor_devices(device_ids):\n",
    "   create_monitoring_table()\n",
    "   create_sensor_table()\n",
    "   \n",
    "   agv_data, oht_data = load_data()\n",
    "   create_and_populate_tables(agv_data, 'agv')\n",
    "   create_and_populate_tables(oht_data, 'oht')\n",
    "   \n",
    "   threads = []\n",
    "   for device_id in device_ids:\n",
    "       thread = threading.Thread(target=monitor_device, args=(device_id,))\n",
    "       thread.daemon = True\n",
    "       thread.start()\n",
    "       threads.append(thread)\n",
    "\n",
    "   try:\n",
    "       while True:\n",
    "           print(\"\\n\\n====== 기기 상태 모니터링 ======\")\n",
    "           print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]\")\n",
    "           \n",
    "           latest_status = get_latest_status()\n",
    "           for device_id, status, timestamp, normal, caution, warning, risk in latest_status:\n",
    "               print(f\"\\n{device_id}:\")\n",
    "               print(f\"상태: {status}\")\n",
    "               print(f\"정상: {normal:.1f}%\")\n",
    "               print(f\"주의: {caution:.1f}%\")\n",
    "               print(f\"경고: {warning:.1f}%\")\n",
    "               print(f\"위험: {risk:.1f}%\")\n",
    "           \n",
    "           time.sleep(30)\n",
    "   except KeyboardInterrupt:\n",
    "       print(\"\\n모니터링을 종료합니다...\")\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "   CORSMiddleware,\n",
    "   allow_origins=[\"*\"],\n",
    "   allow_credentials=True,\n",
    "   allow_methods=[\"*\"],\n",
    "   allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.get(\"/device_status/{device_id}\")\n",
    "async def get_device_status(device_id: str):\n",
    "   conn = sqlite3.connect('sensor_data.db')\n",
    "   cursor = conn.cursor()\n",
    "\n",
    "   cursor.execute('''\n",
    "   SELECT status, timestamp, normal_ratio, caution_ratio, warning_ratio, risk_ratio\n",
    "   FROM device_status\n",
    "   WHERE device_id = ?\n",
    "   ORDER BY timestamp DESC\n",
    "   LIMIT 1\n",
    "   ''', (device_id,))\n",
    "\n",
    "   result = cursor.fetchone()\n",
    "   conn.close()\n",
    "\n",
    "   if not result:\n",
    "       raise HTTPException(status_code=404, detail=\"Device not found\")\n",
    "\n",
    "   return {\n",
    "       \"current_status\": result[0],\n",
    "       \"timestamp\": result[1],\n",
    "       \"counts\": {\n",
    "           \"normal_count\": result[2],\n",
    "           \"caution_count\": result[3],\n",
    "           \"warning_count\": result[4],\n",
    "           \"risk_count\": result[5]\n",
    "       }\n",
    "   }\n",
    "\n",
    "@app.get(\"/device_history/{device_id}\")\n",
    "async def get_device_history(device_id: str):\n",
    "   conn = sqlite3.connect('sensor_data.db')\n",
    "\n",
    "   df = pd.read_sql(f'''\n",
    "   SELECT timestamp, status, normal_ratio, caution_ratio, warning_ratio, risk_ratio\n",
    "   FROM device_status\n",
    "   WHERE device_id = ?\n",
    "   ORDER BY timestamp DESC\n",
    "   LIMIT 10\n",
    "   ''', conn, params=(device_id,))\n",
    "\n",
    "   conn.close()\n",
    "\n",
    "   history = []\n",
    "   for _, row in df.iterrows():\n",
    "       history.append({\n",
    "           \"timestamp\": row[\"timestamp\"],\n",
    "           \"status\": row[\"status\"],\n",
    "           \"counts\": {\n",
    "               \"normal_count\": row[\"normal_ratio\"],\n",
    "               \"caution_count\": row[\"caution_ratio\"],\n",
    "               \"warning_count\": row[\"warning_ratio\"],\n",
    "               \"risk_count\": row[\"risk_ratio\"]\n",
    "           }\n",
    "       })\n",
    "\n",
    "   return history\n",
    "\n",
    "@app.get(\"/sensor_data/{device_id}\")\n",
    "async def get_sensor_data(device_id: str):\n",
    "   conn = sqlite3.connect('sensor_data.db')\n",
    "   \n",
    "   df = pd.read_sql(f'''\n",
    "   SELECT timestampensor_name, sensor_value\n",
    "   FROM sensor_measurements\n",
    "   WHERE device_id = ?\n",
    "   ORDER BY timestamp DESC\n",
    "   ''', conn, params=(device_id,))\n",
    "   \n",
    "   conn.close()\n",
    "   \n",
    "   # 센서 데이터를 센서별로 그룹화\n",
    "   sensor_data = {}\n",
    "   for sensor in df['sensor_name'].unique():\n",
    "       sensor_df = df[df['sensor_name'] == sensor]\n",
    "       sensor_data[sensor] = {\n",
    "           'timestamps': sensor_df['timestamp'].tolist(),\n",
    "           'values': sensor_df['sensor_value'].tolist()\n",
    "       }\n",
    "       \n",
    "   return sensor_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   devices = ['AGV12', 'AGV13', 'AGV14', 'AGV15', 'AGV16']\n",
    "   monitor_devices(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  device_id                   timestamp     sensor_name  sensor_value\n",
      "0     AGV12  2025-01-23 17:53:45.198754             NTC         29.60\n",
      "1     AGV12  2025-01-23 17:53:45.198754           PM1_0         23.00\n",
      "2     AGV12  2025-01-23 17:53:45.198754           PM2_5         32.00\n",
      "3     AGV12  2025-01-23 17:53:45.198754            PM10         50.00\n",
      "4     AGV12  2025-01-23 17:53:45.198754             CT1          1.55\n",
      "5     AGV12  2025-01-23 17:53:45.198754             CT2         74.85\n",
      "6     AGV12  2025-01-23 17:53:45.198754             CT3         48.85\n",
      "7     AGV12  2025-01-23 17:53:45.198754             CT4         19.01\n",
      "8     AGV12  2025-01-23 17:53:45.198754  ex_temperature         25.00\n",
      "9     AGV12  2025-01-23 17:53:45.198754     ex_humidity         31.00\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "db_path = '/Users/hwangeunbi/Desktop/빅프로젝트/MultiModal_AI_1/sensor_data.db'\n",
    "\n",
    "def get_table_data(db_path, table_name):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    query = f\"SELECT * FROM {table_name};\"\n",
    "    try:\n",
    "        df = pd.read_sql(query, conn)\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n",
    "        df = None\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "# 테이블 데이터 가져오기\n",
    "table_name = \"sensor_measurements\"  # 조회하려는 테이블 이름\n",
    "data = get_table_data(db_path, table_name)\n",
    "\n",
    "# 데이터 출력\n",
    "if data is not None:\n",
    "    print(data.head(10))  # 상위 10개 데이터 출력\n",
    "else:\n",
    "    print(f\"{table_name} 테이블에서 데이터를 가져올 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/asyncio/base_events.py\", line 640, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/asyncio/base_events.py\", line 1992, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 10, in <module>\n",
      "    import torch\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/opt/anaconda3/envs/em/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os, sys, time, threading\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "from warnings import filterwarnings\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from MultiModal.dataset import MultimodalTestDataset\n",
    "from MultiModal.model import (\n",
    "  CrossAttention,\n",
    "  SoftLabelEncoder, \n",
    "  ViTFeatureExtractor,\n",
    "  ConditionClassifier\n",
    ")\n",
    "\n",
    "filterwarnings(action='ignore')\n",
    "\n",
    "base_path = './data'\n",
    "db_path = './sensor_data.db'\n",
    "\n",
    "def get_db_connection():\n",
    "  return sqlite3.connect(db_path)\n",
    "\n",
    "def create_monitoring_table():\n",
    "  conn = get_db_connection()\n",
    "  cursor = conn.cursor()\n",
    "  cursor.execute('''\n",
    "  CREATE TABLE IF NOT EXISTS device_status (\n",
    "      device_id TEXT,\n",
    "      status TEXT,\n",
    "      timestamp DATETIME,\n",
    "      normal_ratio REAL,\n",
    "      caution_ratio REAL,\n",
    "      warning_ratio REAL,\n",
    "      risk_ratio REAL,\n",
    "      PRIMARY KEY (device_id, timestamp)\n",
    "  )\n",
    "  ''')\n",
    "  conn.commit()\n",
    "  conn.close()\n",
    "\n",
    "def create_sensor_table():\n",
    "  conn = get_db_connection()\n",
    "  cursor = conn.cursor()\n",
    "  cursor.execute('''\n",
    "  CREATE TABLE IF NOT EXISTS sensor_measurements (\n",
    "      device_id TEXT,\n",
    "      timestamp DATETIME,\n",
    "      sensor_name TEXT,\n",
    "      sensor_value REAL,\n",
    "      PRIMARY KEY (device_id, timestamp, sensor_name)\n",
    "  )\n",
    "  ''')\n",
    "  conn.commit()\n",
    "  conn.close()\n",
    "\n",
    "def create_environment_table():\n",
    "   conn = get_db_connection()\n",
    "   cursor = conn.cursor()\n",
    "   cursor.execute('''\n",
    "   CREATE TABLE IF NOT EXISTS environment_measurements (\n",
    "       timestamp DATETIME,\n",
    "       ex_temperature REAL,\n",
    "       ex_humidity REAL,\n",
    "       ex_illuminance REAL,\n",
    "       PRIMARY KEY (timestamp)\n",
    "   )\n",
    "   ''')\n",
    "   conn.commit()\n",
    "   conn.close()\n",
    "\n",
    "device = 'cpu'\n",
    "model_config = {\n",
    "  'img_dim_h': 120, 'img_dim_w': 160,\n",
    "  'patch_size': 16, 'embed_dim': 128,\n",
    "  'num_heads': 4, 'depth': 6,\n",
    "  'aux_input_dim': 11, 'num_classes': 4\n",
    "}\n",
    "\n",
    "def insert_environment_data(temp, humid, illum):\n",
    "   conn = get_db_connection()\n",
    "   cursor = conn.cursor()\n",
    "   cursor.execute('''\n",
    "   INSERT OR REPLACE INTO environment_measurements \n",
    "   VALUES (datetime('now', 'localtime'), ?, ?, ?)\n",
    "   ''', (temp, humid, illum))\n",
    "   conn.commit()\n",
    "   conn.close()\n",
    "\n",
    "def update_device_status(device_id, status, normal_ratio, caution_ratio, warning_ratio, risk_ratio):\n",
    "  conn = get_db_connection()\n",
    "  cursor = conn.cursor()\n",
    "  cursor.execute('''\n",
    "  INSERT OR REPLACE INTO device_status\n",
    "  VALUES (?, ?, datetime('now', 'localtime'), ?, ?, ?, ?)\n",
    "  ''', (device_id, status, normal_ratio, caution_ratio, warning_ratio, risk_ratio))\n",
    "  conn.commit()\n",
    "  conn.close()\n",
    "\n",
    "def insert_sensor_measurements(device_id, window_data, is_first_window=False):\n",
    "   conn = get_db_connection()\n",
    "   cursor = conn.cursor()\n",
    "   \n",
    "   data_to_insert = window_data if is_first_window else window_data.tail(30)\n",
    "   # 외부 센서 데이터 제외\n",
    "   sensor_columns = [col for col in window_data.columns \n",
    "                    if col not in ['device_id', 'timestamp', 'filenames', \n",
    "                                 'ex_temperature', 'ex_humidity', 'ex_illuminance']]\n",
    "   \n",
    "   timestamp = datetime.now()\n",
    "   for idx, row in data_to_insert.iterrows():\n",
    "       current_timestamp = timestamp + timedelta(seconds=idx)\n",
    "       for sensor in sensor_columns:\n",
    "           cursor.execute('''\n",
    "           INSERT OR REPLACE INTO sensor_measurements \n",
    "           VALUES (?, ?, ?, ?)\n",
    "           ''', (device_id, current_timestamp, sensor, float(row[sensor])))\n",
    "\n",
    "       # 환경 데이터 저장\n",
    "       cursor.execute('''\n",
    "       INSERT OR REPLACE INTO environment_measurements \n",
    "       VALUES (?, ?, ?, ?)\n",
    "       ''', (current_timestamp, float(row['ex_temperature']), \n",
    "             float(row['ex_humidity']), float(row['ex_illuminance'])))\n",
    "           \n",
    "   conn.commit()\n",
    "   conn.close()\n",
    "\n",
    "def get_latest_status():\n",
    "  conn = get_db_connection()\n",
    "  cursor = conn.cursor()\n",
    "  cursor.execute('''\n",
    "  SELECT device_id, status, timestamp, normal_ratio, caution_ratio, warning_ratio, risk_ratio\n",
    "  FROM device_status\n",
    "  GROUP BY device_id\n",
    "  HAVING timestamp = MAX(timestamp)\n",
    "  ''')\n",
    "  results = cursor.fetchall()\n",
    "  conn.close()\n",
    "  return results\n",
    "\n",
    "def load_model(device_type):\n",
    "  model = ConditionClassifier(**model_config)\n",
    "  path = f'Parameters/{device_type}_Best_State_Model.pth'\n",
    "  model.load_state_dict(torch.load(path, map_location='cpu'))\n",
    "  return model.eval()\n",
    "\n",
    "def load_data():\n",
    "  agv_data = {}\n",
    "  for i in range(12, 17):\n",
    "      with open(f'{base_path}/agv{i}_test_df', 'rb') as file:\n",
    "          agv_data[i] = joblib.load(file)\n",
    "          \n",
    "  oht_data = {}\n",
    "  for i in range(12, 17):\n",
    "      with open(f'{base_path}/oht{i}_test_df', 'rb') as file:\n",
    "          oht_data[i] = joblib.load(file)\n",
    "\n",
    "  for dataset in [agv_data, oht_data]:\n",
    "      for key, df in dataset.items():\n",
    "          df.columns = [col.replace('.', '_') for col in df.columns]\n",
    "          if 'filenames' in df.columns:\n",
    "              df['filenames'] = df['filenames'].str.replace('\\\\', '/', regex=False)\n",
    "          df.drop(columns=['device_id', 'collection_date', 'collection_time', 'cumulative_operating_day'], \n",
    "                  inplace=True)\n",
    "  \n",
    "  return agv_data, oht_data\n",
    "\n",
    "def create_and_populate_tables(data_dict, prefix):\n",
    "  conn = get_db_connection()\n",
    "  for i, df in data_dict.items():\n",
    "      table_name = f'{prefix}{i}_table'\n",
    "      df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "      print(f'{table_name}에 데이터 삽입 완료')\n",
    "  conn.close()\n",
    "\n",
    "def check_device_status(device_id):\n",
    "  device_type = 'oht' if 'oht' in device_id.lower() else 'agv'\n",
    "  number = ''.join(filter(str.isdigit, device_id))\n",
    "  table = f\"{device_type}{number}_table\"\n",
    "\n",
    "  conn = get_db_connection()\n",
    "  df = pd.read_sql(f'SELECT * FROM {table}', conn)\n",
    "  conn.close()\n",
    "\n",
    "  window_size = 300\n",
    "  step_size = 30\n",
    "\n",
    "  for start in range(0, len(df) - window_size + 1, step_size):\n",
    "      window = df.iloc[start:start + window_size]\n",
    "      is_first_window = (start == 0)\n",
    "      \n",
    "      dataset = MultimodalTestDataset(window)\n",
    "      dataloader = DataLoader(dataset, batch_size=window_size)\n",
    "      images, sensors = next(iter(dataloader))\n",
    "\n",
    "      model = load_model(device_type.upper())\n",
    "      with torch.no_grad():\n",
    "          prediction = torch.argmax(model(images, sensors), dim=1)\n",
    "\n",
    "      risk = (prediction == 3).sum().item()\n",
    "      warning = (prediction == 2).sum().item()\n",
    "      caution = (prediction == 1).sum().item()\n",
    "      normal = (prediction == 0).sum().item()\n",
    "\n",
    "      total = window_size\n",
    "      risk_ratio = (risk / total) * 100\n",
    "      warning_ratio = (warning / total) * 100\n",
    "      caution_ratio = (caution / total) * 100\n",
    "      normal_ratio = (normal / total) * 100\n",
    "\n",
    "      current_status = \"\"\n",
    "      if device_type == 'agv':\n",
    "          if risk >= 20: current_status = \"위험\"\n",
    "          elif warning >= 60: current_status = \"경고\"\n",
    "          elif caution >= 80: current_status = \"주의\"\n",
    "          else: current_status = \"정상\"\n",
    "      else:\n",
    "          if risk >= 15: current_status = \"위험\"\n",
    "          elif warning >= 50: current_status = \"경고\"\n",
    "          elif caution >= 70: current_status = \"주의\"\n",
    "          else: current_status = \"정상\"\n",
    "\n",
    "      update_device_status(device_id, current_status, normal_ratio, caution_ratio, warning_ratio, risk_ratio)\n",
    "      insert_sensor_measurements(device_id, window, is_first_window)\n",
    "\n",
    "def monitor_device(device_id):\n",
    "  try:\n",
    "      while True:\n",
    "          current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "          print(f\"\\n[{current_time}] {device_id} 분석 시작\")\n",
    "          check_device_status(device_id)\n",
    "          time.sleep(100)\n",
    "  except KeyboardInterrupt:\n",
    "      return\n",
    "\n",
    "def monitor_devices(device_ids):\n",
    "  threads = []\n",
    "  for device_id in device_ids:\n",
    "      thread = threading.Thread(target=monitor_device, args=(device_id,))\n",
    "      thread.daemon = True\n",
    "      thread.start()\n",
    "      threads.append(thread)\n",
    "\n",
    "  try:\n",
    "      while True:\n",
    "          print(\"\\n\\n====== 기기 상태 모니터링 ======\")\n",
    "          print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}]\")\n",
    "          \n",
    "          latest_status = get_latest_status()\n",
    "          for device_id, status, timestamp, normal, caution, warning, risk in latest_status:\n",
    "              print(f\"\\n{device_id}:\")\n",
    "              print(f\"상태: {status}\")\n",
    "              print(f\"정상: {normal:.1f}%\")\n",
    "              print(f\"주의: {caution:.1f}%\")\n",
    "              print(f\"경고: {warning:.1f}%\")\n",
    "              print(f\"위험: {risk:.1f}%\")\n",
    "          \n",
    "          time.sleep(30)\n",
    "  except KeyboardInterrupt:\n",
    "      print(\"\\n모니터링을 종료합니다...\")\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "  CORSMiddleware,\n",
    "  allow_origins=[\"*\"],\n",
    "  allow_credentials=True,\n",
    "  allow_methods=[\"*\"],\n",
    "  allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "   create_monitoring_table()\n",
    "   create_sensor_table() \n",
    "   create_environment_table()\n",
    "   \n",
    "   agv_data, oht_data = load_data()\n",
    "   create_and_populate_tables(agv_data, 'agv')\n",
    "   create_and_populate_tables(oht_data, 'oht')\n",
    "   \n",
    "   devices = ['AGV12', 'AGV13', 'AGV14', 'AGV15', 'AGV16']\n",
    "   monitor_thread = threading.Thread(target=monitor_devices, args=(devices,))\n",
    "   monitor_thread.daemon = True\n",
    "   monitor_thread.start()\n",
    "\n",
    "@app.get(\"/device_status/{device_id}\")\n",
    "async def get_device_status(device_id: str):\n",
    "  conn = get_db_connection()\n",
    "  cursor = conn.cursor()\n",
    "\n",
    "  cursor.execute('''\n",
    "  SELECT status, timestamp, normal_ratio, caution_ratio, warning_ratio, risk_ratio\n",
    "  FROM device_status\n",
    "  WHERE device_id = ?\n",
    "  ORDER BY timestamp DESC\n",
    "  LIMIT 1\n",
    "  ''', (device_id,))\n",
    "\n",
    "  result = cursor.fetchone()\n",
    "  conn.close()\n",
    "\n",
    "  if not result:\n",
    "      raise HTTPException(status_code=404, detail=\"Device not found\")\n",
    "\n",
    "  return {\n",
    "      \"current_status\": result[0],\n",
    "      \"timestamp\": result[1],\n",
    "      \"counts\": {\n",
    "          \"normal_count\": result[2],\n",
    "          \"caution_count\": result[3],\n",
    "          \"warning_count\": result[4],\n",
    "          \"risk_count\": result[5]\n",
    "      }\n",
    "  }\n",
    "\n",
    "@app.get(\"/device_history/{device_id}\")\n",
    "async def get_device_history(device_id: str):\n",
    "  conn = get_db_connection()\n",
    "\n",
    "  df = pd.read_sql(f'''\n",
    "  SELECT timestamp, status, normal_ratio, caution_ratio, warning_ratio, risk_ratio\n",
    "  FROM device_status\n",
    "  WHERE device_id = ?\n",
    "  ORDER BY timestamp DESC\n",
    "  LIMIT 10\n",
    "  ''', conn, params=(device_id,))\n",
    "\n",
    "  conn.close()\n",
    "\n",
    "  history = []\n",
    "  for _, row in df.iterrows():\n",
    "      history.append({\n",
    "          \"timestamp\": row[\"timestamp\"],\n",
    "          \"status\": row[\"status\"],\n",
    "          \"counts\": {\n",
    "              \"normal_count\": row[\"normal_ratio\"],\n",
    "              \"caution_count\": row[\"caution_ratio\"],\n",
    "              \"warning_count\": row[\"warning_ratio\"],\n",
    "              \"risk_count\": row[\"risk_ratio\"]\n",
    "          }\n",
    "      })\n",
    "\n",
    "  return history\n",
    "\n",
    "@app.get(\"/sensor_data/{device_id}\")\n",
    "async def get_sensor_data(device_id: str):\n",
    "  conn = get_db_connection()\n",
    "  \n",
    "  df = pd.read_sql(f'''\n",
    "  SELECT timestamp, sensor_name, sensor_value\n",
    "  FROM sensor_measurements\n",
    "  WHERE device_id = ?\n",
    "  ORDER BY timestamp DESC\n",
    "  LIMIT 900\n",
    "  ''', conn, params=(device_id,))\n",
    "  \n",
    "  conn.close()\n",
    "  \n",
    "  sensor_data = {}\n",
    "  for sensor in df['sensor_name'].unique():\n",
    "      sensor_df = df[df['sensor_name'] == sensor]\n",
    "      sensor_data[sensor] = {\n",
    "          'timestamps': sensor_df['timestamp'].tolist(),\n",
    "          'values': sensor_df['sensor_value'].tolist()\n",
    "      }\n",
    "      \n",
    "  return sensor_data\n",
    "\n",
    "@app.get(\"/environment_data\")\n",
    "async def get_environment_data():\n",
    "   conn = get_db_connection()\n",
    "   df = pd.read_sql('''\n",
    "   SELECT * FROM environment_measurements \n",
    "   ORDER BY timestamp DESC \n",
    "   LIMIT 900\n",
    "   ''', conn)\n",
    "   conn.close()\n",
    "   \n",
    "   return {\n",
    "       \"timestamps\": df['timestamp'].tolist(),\n",
    "       \"ex_temperature\": df['ex_temperature'].tolist(),\n",
    "       \"ex_temperature\": df['ex_temperature'].tolist(),\n",
    "       \"ex_temperature\": df['ex_temperature'].tolist()\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in thread Thread-5 (monitor_device):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2674, in execute\n",
      "Thread-4 (monitor_device):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2674, in execute\n",
      "Exception in thread Thread-6 (monitor_device):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2674, in execute\n",
      "Exception in thread Thread-7 (monitor_device):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2674, in execute\n",
      "Exception in thread Thread-8 (monitor_device):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2674, in execute\n",
      "    cur.execute(sql, *args)\n",
      "sqlite3.OperationalError: no such table: agv15_table\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    cur.execute(sql, *args)\n",
      "sqlite3.OperationalError: no such table: agv16_table\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    cur.execute(sql, *args)\n",
      "sqlite3.OperationalError: no such table: agv12_table\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    cur.execute(sql, *args)\n",
      "sqlite3.OperationalError: no such table: agv14_table\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    cur.execute(sql, *args)\n",
      "sqlite3.OperationalError: no such table: agv13_table\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/threading.py\", line 1012, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/threading.py\", line 1012, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 237, in monitor_device\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 237, in monitor_device\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/threading.py\", line 1012, in run\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 188, in check_device_status\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 188, in check_device_status\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 237, in monitor_device\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 237, in monitor_device\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 188, in check_device_status\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 706, in read_sql\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 237, in monitor_device\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 706, in read_sql\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 188, in check_device_status\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 706, in read_sql\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 706, in read_sql\n",
      "  File \"/var/folders/8n/xfc3hjdn5pq9ch7rw__k4fyh0000gn/T/ipykernel_3062/2515050444.py\", line 188, in check_device_status\n",
      "    return pandas_sql.read_query(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2738, in read_query\n",
      "    return pandas_sql.read_query(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2738, in read_query\n",
      "    return pandas_sql.read_query(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2738, in read_query\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 706, in read_sql\n",
      "    cursor = self.execute(sql, params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2686, in execute\n",
      "    raise ex from exc\n",
      "pandas.errors.DatabaseError: Execution failed on sql 'SELECT * FROM agv15_table': no such table: agv15_table\n",
      "    cursor = self.execute(sql, params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2686, in execute\n",
      "    cursor = self.execute(sql, params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2686, in execute\n",
      "    return pandas_sql.read_query(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2738, in read_query\n",
      "    raise ex from exc\n",
      "pandas.errors.DatabaseError: Execution failed on sql 'SELECT * FROM agv12_table': no such table: agv12_table\n",
      "    return pandas_sql.read_query(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2738, in read_query\n",
      "    raise ex from exc\n",
      "pandas.errors.DatabaseError: Execution failed on sql 'SELECT * FROM agv16_table': no such table: agv16_table\n",
      "    cursor = self.execute(sql, params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2686, in execute\n",
      "    cursor = self.execute(sql, params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/em/lib/python3.12/site-packages/pandas/io/sql.py\", line 2686, in execute\n",
      "    raise ex from exc\n",
      "pandas.errors.DatabaseError: Execution failed on sql 'SELECT * FROM agv14_table': no such table: agv14_table\n",
      "    raise ex from exc\n",
      "pandas.errors.DatabaseError: Execution failed on sql 'SELECT * FROM agv13_table': no such table: agv13_table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2025-01-24 15:49:14] AGV12 분석 시작\n",
      "\n",
      "[2025-01-24 15:49:14] AGV13 분석 시작\n",
      "\n",
      "[2025-01-24 15:49:14] AGV14 분석 시작\n",
      "\n",
      "[2025-01-24 15:49:14] AGV15 분석 시작\n",
      "\n",
      "[2025-01-24 15:49:14] AGV16 분석 시작\n",
      "\n",
      "\n",
      "====== 기기 상태 모니터링 ======\n",
      "[2025-01-24 15:49:14]\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "no such table: device_status",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m    devices \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGV12\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGV13\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGV14\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGV15\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGV16\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m    \u001b[43mmonitor_devices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 255\u001b[0m, in \u001b[0;36mmonitor_devices\u001b[0;34m(device_ids)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m====== 기기 상태 모니터링 ======\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 255\u001b[0m latest_status \u001b[38;5;241m=\u001b[39m \u001b[43mget_latest_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m device_id, status, timestamp, normal, caution, warning, risk \u001b[38;5;129;01min\u001b[39;00m latest_status:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdevice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 137\u001b[0m, in \u001b[0;36mget_latest_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m conn \u001b[38;5;241m=\u001b[39m get_db_connection()\n\u001b[1;32m    136\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[0;32m--> 137\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;43mSELECT device_id, status, timestamp, normal_ratio, caution_ratio, warning_ratio, risk_ratio\u001b[39;49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;43mFROM device_status\u001b[39;49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;43mGROUP BY device_id\u001b[39;49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;43mHAVING timestamp = MAX(timestamp)\u001b[39;49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;43m\u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m results \u001b[38;5;241m=\u001b[39m cursor\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m    144\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: device_status"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "   devices = ['AGV12', 'AGV13', 'AGV14', 'AGV15', 'AGV16']\n",
    "   monitor_devices(devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "em",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
